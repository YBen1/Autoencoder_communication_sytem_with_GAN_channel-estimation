{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MA_GAN_estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/MA_GAN/blob/master/MA_GAN_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-49-RQG7bEV",
        "colab_type": "code",
        "outputId": "8698bc19-140e-45d5-ecfe-6e32e8ff73c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-rc0\n",
        "!pip install -q pyyaml h5py\n",
        "#!pip install -q tf_nightly\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-rc0 in /usr/local/lib/python3.6/dist-packages (2.0.0rc0)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a20190807,>=1.15.0a20190806 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0a20190806)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.33.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.14.0.dev2019080601)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.0.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.16.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (0.15.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0-rc0) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9PJHQS0UCJ",
        "colab_type": "text"
      },
      "source": [
        "## System funktionsweise Allgemeine Daten\n",
        "\n",
        "#### Rauschen\n",
        "genarats-> **shape**: batch_size * number_of_real_channels_uses_per_message \\\\\n",
        "and does a average power normalization\n",
        "\n",
        "\n",
        "#### Generator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,n)   \\\\\n",
        "Loss-Function:\n",
        "\n",
        "#### Discriminator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,1)  \\\\\n",
        "Loss-Function:\n",
        "\n",
        "\n",
        "#### Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses **What is meant by that??** \\\\\n",
        "$N$ - L채nge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Y2r6qBAgKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 4       # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**k\n",
        "n = 2       # Number of real channel uses per message\n",
        "seed = 2    # Seed RNG reproduce identical results\n",
        "D_nb_weights = 32\n",
        "G_nb_weights = 32\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "x = tf.random.normal((batch_size,n))    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY9sHsfWT8By",
        "colab_type": "text"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "outputId": "b111bf06-2b43-440e-fddb-6032eba559fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "#def generator(x):\n",
        "    # Concatenate z and y\n",
        "#    G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "#    inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "    #dense NN\n",
        "#    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
        "#    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "#    G_lin = tf.matmul(G_h2, G_W3) + G_b3\n",
        "    #G_prob = tf.nn.sigmoid(G_lin)\n",
        "#    return G_lin\n",
        "\n",
        "def generator_noise(input):\n",
        "  G_n = tf.random.normal([tf.shape(input)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "  inputs = tf.concat(values=[input, G_n], axis=1)\n",
        "  return inputs\n",
        "    \n",
        "def generator(x = tf.keras.Input(shape=(batch_size,n)),training = False):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Lambda(generator_noise))\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))#, input_shape=(2*n,))\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True,  activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=False, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "generator= generator()\n",
        "test = generator(x)\n",
        "print(test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.46109313 0.46139178]\n",
            " [0.5640976  0.49818423]\n",
            " [0.5384959  0.4722582 ]\n",
            " [0.5291493  0.5304533 ]\n",
            " [0.5085808  0.49630043]\n",
            " [0.5194655  0.52837825]\n",
            " [0.4086768  0.36144972]\n",
            " [0.5274147  0.52902603]\n",
            " [0.5280123  0.51495135]\n",
            " [0.59059936 0.55196995]\n",
            " [0.527848   0.5045744 ]\n",
            " [0.5594921  0.45417446]\n",
            " [0.53903466 0.41238734]\n",
            " [0.4797062  0.4262348 ]\n",
            " [0.53213054 0.41969734]\n",
            " [0.49859303 0.4299028 ]\n",
            " [0.50411695 0.5132177 ]\n",
            " [0.42387855 0.444058  ]\n",
            " [0.5300688  0.44966546]\n",
            " [0.5075823  0.513632  ]\n",
            " [0.5743154  0.5389375 ]\n",
            " [0.4145344  0.3723564 ]\n",
            " [0.4776653  0.52187365]\n",
            " [0.47606838 0.44934514]\n",
            " [0.4993501  0.50872827]\n",
            " [0.48829684 0.4649793 ]\n",
            " [0.5145876  0.51299226]\n",
            " [0.56271076 0.39320835]\n",
            " [0.38247877 0.36551905]\n",
            " [0.49693912 0.49500066]\n",
            " [0.5765868  0.48699763]\n",
            " [0.5301109  0.43966848]\n",
            " [0.49013013 0.5024938 ]\n",
            " [0.469551   0.37174052]\n",
            " [0.44433272 0.4963764 ]\n",
            " [0.49519277 0.42926928]\n",
            " [0.51143724 0.46367413]\n",
            " [0.5404545  0.5010194 ]\n",
            " [0.5759426  0.5009629 ]\n",
            " [0.5417402  0.5182171 ]\n",
            " [0.48918656 0.4535937 ]\n",
            " [0.4460078  0.38494837]\n",
            " [0.48853934 0.5146476 ]\n",
            " [0.49512386 0.5173413 ]\n",
            " [0.5297888  0.5088791 ]\n",
            " [0.47230777 0.26461157]\n",
            " [0.5382593  0.4764776 ]\n",
            " [0.56778777 0.42894834]\n",
            " [0.47331816 0.45751745]\n",
            " [0.47065023 0.46243438]\n",
            " [0.5081729  0.5238813 ]\n",
            " [0.5665487  0.52820706]\n",
            " [0.5523866  0.49865466]\n",
            " [0.51370853 0.5149602 ]\n",
            " [0.52902806 0.49327734]\n",
            " [0.43879443 0.4422506 ]\n",
            " [0.47501162 0.3391186 ]\n",
            " [0.5297739  0.5241759 ]\n",
            " [0.55833775 0.54336137]\n",
            " [0.4437362  0.37103975]\n",
            " [0.4699788  0.5100457 ]\n",
            " [0.53332037 0.46230707]\n",
            " [0.49609852 0.49872592]\n",
            " [0.60117364 0.45671916]\n",
            " [0.5417536  0.512488  ]\n",
            " [0.5612532  0.4678499 ]\n",
            " [0.4231683  0.38037723]\n",
            " [0.5254036  0.4990456 ]\n",
            " [0.5041493  0.4802266 ]\n",
            " [0.55547756 0.48316285]\n",
            " [0.48860213 0.47320467]\n",
            " [0.5583729  0.5325836 ]\n",
            " [0.4576035  0.40315118]\n",
            " [0.47221684 0.48226133]\n",
            " [0.5577781  0.4664653 ]\n",
            " [0.34678316 0.24541968]\n",
            " [0.52134013 0.51037276]\n",
            " [0.5750917  0.40270364]\n",
            " [0.4842785  0.50273937]\n",
            " [0.42449424 0.34820116]\n",
            " [0.46872362 0.50326604]\n",
            " [0.5254161  0.4891543 ]\n",
            " [0.50713485 0.5040805 ]\n",
            " [0.5023778  0.42974144]\n",
            " [0.56275505 0.5017509 ]\n",
            " [0.4716546  0.503702  ]\n",
            " [0.5149665  0.45631933]\n",
            " [0.49886125 0.4333297 ]\n",
            " [0.5137799  0.45194736]\n",
            " [0.49296218 0.4420597 ]\n",
            " [0.6033088  0.5296476 ]\n",
            " [0.5046296  0.50589544]\n",
            " [0.53950906 0.44831324]\n",
            " [0.48263934 0.44775674]\n",
            " [0.46184927 0.27042463]\n",
            " [0.42798388 0.37869394]\n",
            " [0.49552742 0.4448432 ]\n",
            " [0.42571583 0.39678663]\n",
            " [0.45925078 0.30818492]\n",
            " [0.5055942  0.5455059 ]], shape=(100, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbjziKpv35v",
        "colab_type": "text"
      },
      "source": [
        "### Help Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rHD990Y-w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "#numpy version of kl divergence\n",
        "def kl_divergence_np(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w=1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return np.sum(p * np.log(p / q))\n",
        "\n",
        "#tensorflow version of kl divergence\n",
        "def kl_divergence_tf(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w = 1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return tf.reduce_sum(p * tf.log(p / q))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUzHiyUXLoP",
        "colab_type": "text"
      },
      "source": [
        "## Channels as Black-Box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63_fJJRXL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_SNR_dB = 6\n",
        "noise_std = EbNo2Sigma(train_SNR_dB)\n",
        "\n",
        "def real_channel(x):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzh-JZgfXSqN",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator\n",
        "Model definition and creating discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concc(y,x):  \n",
        "  inputs = tf.concat(values=[y,x], axis=1)\n",
        "  return inputs\n",
        "\n",
        "def get_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu',input_shape=((2*n,))))\n",
        "  model.add(tf.keras.layers.Dense(16,use_bias=True,  activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid'))\n",
        "  return model\n",
        "discriminator = get_discriminator()\n",
        "\n",
        "#def discriminator(y,x):\n",
        "#    # Concatenate x and y\n",
        "#    inputs = tf.concat(values=[y,x], axis=1)\n",
        "#    #dense NN\n",
        "#    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "#    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "#    D_prob = tf.nn.sigmoid(D_logit)\n",
        "#    return D_prob, D_logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnlfRYuYC8R",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation, 체berhaupt noch relevant??!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcnkBIUXYa_",
        "colab_type": "text"
      },
      "source": [
        "## discriminator desicion????\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7im8FYMXeOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xQt6M5Xd9P",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss\n",
        "strongly inspiered by: \\\\\n",
        "https://www.tensorflow.org/beta/tutorials/generative/dcgan?hl=en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36yIH7Q3FiEq",
        "colab_type": "text"
      },
      "source": [
        "## defining Loss. TODO:\n",
        "compile the Model with the right loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCLjUsVDzAn",
        "colab_type": "code",
        "outputId": "58fca094-d6d5-4f88-cf6f-4a3f59ee1b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  \n",
        "fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=-1)\n",
        "\n",
        "print(real_training_data.shape,fake_training_data.shape)\n",
        "real_output = discriminator(real_training_data)\n",
        "fake_output = discriminator(fake_training_data)\n",
        "print(fake_output)\n",
        "#print(real_output, fake_output)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 4) (100, 4)\n",
            "tf.Tensor(\n",
            "[[0.43171448]\n",
            " [0.42564246]\n",
            " [0.45315316]\n",
            " [0.44333774]\n",
            " [0.35031766]\n",
            " [0.43838906]\n",
            " [0.42375702]\n",
            " [0.4522534 ]\n",
            " [0.38115877]\n",
            " [0.4310927 ]\n",
            " [0.45088425]\n",
            " [0.4374511 ]\n",
            " [0.46071082]\n",
            " [0.4136397 ]\n",
            " [0.37760836]\n",
            " [0.42867538]\n",
            " [0.3850702 ]\n",
            " [0.45799187]\n",
            " [0.37391722]\n",
            " [0.4475627 ]\n",
            " [0.4374724 ]\n",
            " [0.45497382]\n",
            " [0.4315776 ]\n",
            " [0.41336933]\n",
            " [0.44209206]\n",
            " [0.45354265]\n",
            " [0.39026222]\n",
            " [0.44616538]\n",
            " [0.3883156 ]\n",
            " [0.45519927]\n",
            " [0.45055714]\n",
            " [0.42013437]\n",
            " [0.4420087 ]\n",
            " [0.4186934 ]\n",
            " [0.4581687 ]\n",
            " [0.44158956]\n",
            " [0.44933274]\n",
            " [0.4538879 ]\n",
            " [0.3458306 ]\n",
            " [0.41672224]\n",
            " [0.41200513]\n",
            " [0.44958013]\n",
            " [0.44412896]\n",
            " [0.40644142]\n",
            " [0.41699827]\n",
            " [0.4511185 ]\n",
            " [0.44707194]\n",
            " [0.4122451 ]\n",
            " [0.4548698 ]\n",
            " [0.42626217]\n",
            " [0.4538915 ]\n",
            " [0.43298376]\n",
            " [0.43728915]\n",
            " [0.44156045]\n",
            " [0.44150192]\n",
            " [0.45437476]\n",
            " [0.43233162]\n",
            " [0.4468142 ]\n",
            " [0.41526642]\n",
            " [0.4418656 ]\n",
            " [0.4351177 ]\n",
            " [0.43062174]\n",
            " [0.3698519 ]\n",
            " [0.43615752]\n",
            " [0.42826578]\n",
            " [0.45215383]\n",
            " [0.39718315]\n",
            " [0.42283887]\n",
            " [0.40891093]\n",
            " [0.4346969 ]\n",
            " [0.41021168]\n",
            " [0.44009617]\n",
            " [0.4368622 ]\n",
            " [0.3940988 ]\n",
            " [0.41780728]\n",
            " [0.41949397]\n",
            " [0.41730914]\n",
            " [0.42440003]\n",
            " [0.4537233 ]\n",
            " [0.42774454]\n",
            " [0.38541627]\n",
            " [0.42829776]\n",
            " [0.44851053]\n",
            " [0.4413071 ]\n",
            " [0.43239838]\n",
            " [0.40862355]\n",
            " [0.42117706]\n",
            " [0.39430344]\n",
            " [0.4006942 ]\n",
            " [0.40377814]\n",
            " [0.40980446]\n",
            " [0.44346613]\n",
            " [0.41919568]\n",
            " [0.4382454 ]\n",
            " [0.4357782 ]\n",
            " [0.43557763]\n",
            " [0.4387508 ]\n",
            " [0.43872684]\n",
            " [0.43618324]\n",
            " [0.44686773]], shape=(100, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERelQ5oTEMtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  loss= -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "  return loss\n",
        "  \n",
        "def generator_loss(fake_output, generator):\n",
        "  loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "  return loss\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gktABNcepz5c",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation with Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgM9lv-dp1PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_evaluation_data(batch_size=100):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "  #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "  #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "  fake_eval_data = tf.concat(values=[generator(x), x], axis=1)\n",
        "  real_eval_data = tf.concat(values=[real_channel(x), x], axis=1) #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "  inputs = x\n",
        "  return  real_eval_data, fake_eval_data, inputs \n",
        "\n",
        "\n",
        "\n",
        "def get_evaluation_data(evaluation_per_epochs):\n",
        "  real_eval_data = []\n",
        "  fake_eval_data  = []\n",
        "  inputs = []\n",
        "  for i in range(evaluation_per_epochs):\n",
        "    data = generate_evaluation_data()\n",
        "    real_eval_data.append(data[0])\n",
        "    fake_eval_data.append(data[1])\n",
        "    inputs.append(data[2])\n",
        "  return real_eval_data, fake_eval_data, inputs\n",
        "\n",
        "\n",
        "def test_eval(real_eval_data,fake_eval_data,inputs):\n",
        "  hist_range = 2\n",
        "  \n",
        "  inputs_ = tf.concat(values=[inputs, inputs],  axis=-1)\n",
        "  \n",
        "  fake_output_hist = np.mean(fake_eval_data,axis=1)  # Changed from 0 to 1\n",
        "  real_output_hist = np.mean(real_eval_data,axis=1)\n",
        "  inputs_hist = np.mean(inputs_,axis=1)\n",
        "    \n",
        "  fake_output_hist1 = np.reshape( fake_output_hist,[-1,])\n",
        "  real_output_hist1 = np.reshape( real_output_hist,[-1,])\n",
        "    \n",
        "  plt.hist(fake_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "  \n",
        "  fake_noise = np.reshape( fake_output_hist - inputs_hist,[-1,])\n",
        "  real_noise = np.reshape( real_output_hist - inputs_hist,[-1,])\n",
        "   \n",
        "  plt.hist(fake_noise,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_noise,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution after subtracting Inpus_noise\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "    \n",
        "    #print(\"decision for fake data was %d: and for real data was %d:\" % (decision_fake, decision_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQWOgXnl62o",
        "colab_type": "text"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sl75gEZl6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "steps_per_epoches = 50\n",
        "batch_size = 100\n",
        "\n",
        "evaluation_per_epochs = 100\n",
        "\n",
        "noise_dim = n        #noch 채ndern wenn ich noise 채ndere\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooDukkHvmduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, steps_per_epoches , batch_size, generator, discriminator):\n",
        "  start = time.time()\n",
        "  counter = 0\n",
        "  epoch = 0\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    #print(massege_batch)\n",
        "    counter += 1\n",
        "    train_step(epoch, steps_per_epoches , batch_size, generator, discriminator) \n",
        "    if counter%5 == 0:\n",
        "      print(\"counter %d:\" % (counter))\n",
        "    if counter%5 == 0:\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "    print ('Time for epoch {} is {} sec,'.format(epoch + 1, time.time()-start))\n",
        "    \n",
        "    \n",
        "       \n",
        "  checkpoint_path = \"training_1/cp.ckpt\"\n",
        "  checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                 save_weights_only=False,\n",
        "                                                 verbose=1)    \n",
        "\n",
        "  print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        "    \n",
        "   \n",
        "\n",
        "  # Generate after the final epoch\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7H98i7TmVxw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XxSryMYmCkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "#def train_step(massege_batch,counter):\n",
        "#    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "    #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "#    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "\n",
        "\n",
        " #   with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:           #tapes the gradient of the generaor an the discriminator\n",
        "  #    fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      \n",
        " #     real_output = discriminator(real_training_data, training=True)\n",
        " #     fake_output = discriminator(fake_training_data, training=True)\n",
        "\n",
        " #     disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        " #     gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        " #     gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        " #     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  #    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  #    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJno--QQh4_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "\n",
        "def train_step(epoch, steps_per_epoches , batch_size, generator, discriminator):\n",
        "\n",
        "    \n",
        "  for j in range(steps_per_epoches):\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      real_output = discriminator(real_training_data, training=True)\n",
        "      fake_output = discriminator(fake_training_data, training=True)\n",
        "      disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "      gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "      #print(disc_loss, gen_loss)\n",
        "          \n",
        "    \n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "      \n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGMDjc1metC",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82FQj3Jmvxx",
        "colab_type": "code",
        "outputId": "9da3b8ce-47a6-468d-a906-6298573607e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "train(epochs, steps_per_epoches , batch_size, generator, discriminator)\n",
        "\n",
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 1 is 31.85362935066223 sec,\n",
            "Time for epoch 2 is 18.646808385849 sec,\n",
            "Time for epoch 3 is 18.743465423583984 sec,\n",
            "Time for epoch 4 is 20.247108936309814 sec,\n",
            "counter 5:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYBTcIiKB+f8awNQIoSG6mgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 5 is 32.07296395301819 sec,\n",
            "Time for epoch 6 is 20.72519850730896 sec,\n",
            "Time for epoch 7 is 18.803030967712402 sec,\n",
            "Time for epoch 8 is 21.476558923721313 sec,\n",
            "Time for epoch 9 is 18.83250904083252 sec,\n",
            "counter 10:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzP8H4kGrR3ulx88AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 10 is 33.645373582839966 sec,\n",
            "Time for the training is 33.645700454711914 sec,\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_3 (Lambda)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             multiple                  160       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             multiple                  1056      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             multiple                  64        \n",
            "=================================================================\n",
            "Total params: 1,280\n",
            "Trainable params: 1,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 32)                160       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 704\n",
            "Trainable params: 704\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 3min 53s, sys: 3.38 s, total: 3min 57s\n",
            "Wall time: 3min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKRrixvwnA_m",
        "colab_type": "text"
      },
      "source": [
        "### Restore the latest checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esovpz32jW6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#discriminator = keras.models.load_model('my_discriminator.h5')\n",
        "#generator = keras.models.load_model('my_generator.h5')\n",
        "#generator1 = generator(x)\n",
        "#generator1.fit(x, real_channel(x),  epochs = 10,\n",
        "#          validation_data = (x,real_channel(x)),\n",
        "#          callbacks = [cp_callback])\n",
        "\n",
        "#real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "#test_eval(real_eval_data, fake_eval_data, inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw6Rt5z3Rjud",
        "colab_type": "code",
        "outputId": "d6cc34ab-31ae-4284-c1e5-e4c9a05bf3f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#print(x)\n",
        "real_c = real_channel(x)\n",
        "fake_c = generator(x)\n",
        "\n",
        "print(fake_c)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[9.98146653e-01 9.99848127e-01]\n",
            " [9.61282730e-01 3.75509262e-06]\n",
            " [4.22111154e-03 9.99702394e-01]\n",
            " [7.71880150e-06 9.99998689e-01]\n",
            " [2.80141830e-06 0.00000000e+00]\n",
            " [0.00000000e+00 9.15221870e-02]\n",
            " [0.00000000e+00 6.63779497e-01]\n",
            " [0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 5.96046448e-08]\n",
            " [7.83801079e-06 8.94919515e-01]\n",
            " [0.00000000e+00 5.16235828e-04]\n",
            " [9.41391349e-01 6.25848770e-07]\n",
            " [1.50996447e-03 9.00860548e-01]\n",
            " [0.00000000e+00 1.82270706e-02]\n",
            " [8.81024718e-01 8.50230217e-01]\n",
            " [1.41441822e-03 8.53144825e-02]\n",
            " [5.01525939e-01 9.93051589e-01]\n",
            " [5.75184822e-06 3.95100832e-01]\n",
            " [2.60143846e-01 9.99997497e-01]\n",
            " [2.60770321e-05 7.82553554e-02]\n",
            " [9.96646166e-01 9.91435766e-01]\n",
            " [1.91405714e-02 7.15804100e-03]\n",
            " [0.00000000e+00 1.00423545e-01]\n",
            " [1.24894679e-02 2.17168927e-02]\n",
            " [9.10758972e-05 0.00000000e+00]\n",
            " [6.46710396e-06 4.22477722e-03]\n",
            " [0.00000000e+00 0.00000000e+00]\n",
            " [2.98023224e-08 0.00000000e+00]\n",
            " [0.00000000e+00 7.30010867e-03]\n",
            " [0.00000000e+00 1.92921162e-02]\n",
            " [9.99477148e-01 2.19374895e-04]\n",
            " [0.00000000e+00 7.90312886e-03]\n",
            " [2.89618969e-04 9.99949515e-01]\n",
            " [1.66482031e-02 9.28235829e-01]\n",
            " [4.02841270e-02 0.00000000e+00]\n",
            " [2.08456188e-01 7.44608581e-01]\n",
            " [0.00000000e+00 5.08725643e-05]\n",
            " [9.95010734e-01 1.43349171e-05]\n",
            " [7.69189000e-03 7.19796121e-02]\n",
            " [9.58391309e-01 3.06189060e-04]\n",
            " [4.55451012e-03 9.98645604e-01]\n",
            " [1.31968051e-01 1.66240335e-03]\n",
            " [9.95628715e-01 8.21879506e-03]\n",
            " [9.97736931e-01 5.36015630e-03]\n",
            " [1.82485849e-01 1.08669698e-02]\n",
            " [0.00000000e+00 2.38418579e-06]\n",
            " [6.22868538e-06 2.68220901e-07]\n",
            " [3.59714031e-05 4.31662798e-03]\n",
            " [6.90216064e-01 5.26885986e-01]\n",
            " [0.00000000e+00 8.40720534e-03]\n",
            " [9.91846502e-01 9.93247032e-02]\n",
            " [9.99711633e-01 2.07996964e-02]\n",
            " [1.75035596e-02 8.02723229e-01]\n",
            " [0.00000000e+00 1.81794167e-06]\n",
            " [1.95422173e-02 4.83356088e-01]\n",
            " [1.58193707e-03 6.40583277e-01]\n",
            " [1.43051147e-05 5.34951687e-03]\n",
            " [2.80152559e-02 9.17269349e-01]\n",
            " [4.36048150e-01 9.98417616e-01]\n",
            " [3.96370888e-06 1.19209290e-07]\n",
            " [9.97536421e-01 2.89678574e-05]\n",
            " [1.29687786e-03 9.40458894e-01]\n",
            " [5.91053009e-01 1.57058239e-04]\n",
            " [6.78033412e-01 9.98107910e-01]\n",
            " [7.26814806e-01 1.98483467e-05]\n",
            " [0.00000000e+00 0.00000000e+00]\n",
            " [9.96844053e-01 9.74154830e-01]\n",
            " [9.97996628e-01 4.82797623e-05]\n",
            " [3.57627869e-07 9.96719480e-01]\n",
            " [9.28312540e-04 9.84467268e-01]\n",
            " [2.14781761e-02 2.00815201e-02]\n",
            " [2.38418579e-07 1.86026096e-04]\n",
            " [7.71999359e-04 8.81818295e-01]\n",
            " [0.00000000e+00 2.21073627e-04]\n",
            " [1.16513073e-02 9.96481538e-01]\n",
            " [1.31130219e-06 2.93344259e-04]\n",
            " [9.51538682e-01 8.88675869e-01]\n",
            " [2.64018774e-04 9.99604523e-01]\n",
            " [3.31461430e-04 0.00000000e+00]\n",
            " [1.28685683e-01 0.00000000e+00]\n",
            " [9.98996019e-01 2.08616257e-07]\n",
            " [4.68671322e-04 9.90404010e-01]\n",
            " [1.14635527e-02 4.31851745e-02]\n",
            " [0.00000000e+00 0.00000000e+00]\n",
            " [9.85295236e-01 1.71138644e-02]\n",
            " [0.00000000e+00 3.53496522e-01]\n",
            " [5.68376780e-02 9.75506783e-01]\n",
            " [1.49011612e-07 9.94089961e-01]\n",
            " [2.53319740e-06 9.97094512e-01]\n",
            " [0.00000000e+00 2.14105844e-03]\n",
            " [5.76958597e-01 9.23871994e-07]\n",
            " [3.56703997e-04 1.36196613e-05]\n",
            " [0.00000000e+00 3.09944153e-06]\n",
            " [0.00000000e+00 0.00000000e+00]\n",
            " [3.14019620e-02 0.00000000e+00]\n",
            " [6.33026958e-02 1.22249126e-03]\n",
            " [3.10973793e-01 9.97939467e-01]\n",
            " [5.45382500e-06 0.00000000e+00]\n",
            " [0.00000000e+00 5.23903966e-03]], shape=(100, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmP50TkiAg-C",
        "colab_type": "text"
      },
      "source": [
        "## AE\n",
        "Die Idee sollte sein das Training auf den encoder und decoder einzuschr채nken. Jedoch soll **end-to-end** trainiert werden, hierf체r sollte vllt eine art Funktion eingesetzt werden, welche 체ber die GAN's Layer zur체ck geht.\n",
        "Muss ich hierf체r die Layer nochmals einzeln definieren?\n",
        "\n",
        "\n",
        "***Vermutung: Der Ausgang hat die 8fache dimension des Eingangs-> daher nur 1/8 richtig oder 7/8 richtig*** \\\\\n",
        "**zu kl채ren: was passiert in meinem AE dass sie dei dimension ver8-facht von (1000,8) zu (8000,n)**\n",
        "**Kontrollieren was der output von meinem GAN ist**\n",
        "**Add complexity for higher rubustness**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "outputId": "b01aec28-05bd-4fd4-a7d2-5af5f9e6ffaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "def get_encoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[M]))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=False, activation=None))\n",
        "  model.add(tf.keras.layers.Lambda(lambda x : tf.divide(x, tf.sqrt(2*tf.reduce_mean(tf.square(x))))))\n",
        "  return model\n",
        "\n",
        "def get_decoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[n]))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=False, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "encoder = get_encoder()\n",
        "decoder = get_decoder()\n",
        "\n",
        "encoder.summary()\n",
        "generator.summary()\n",
        "decoder.summary()\n",
        "   \n",
        "def get_AE(encoder, generator, decoder):\n",
        "  AE_model = tf.keras.Sequential()\n",
        "  AE_model.add(encoder)\n",
        "  AE_model.add(tf.keras.layers.Lambda(generator))\n",
        "  AE_model.add(decoder)\n",
        "  return AE_model\n",
        "          \n",
        "    \n",
        "def generate_data_vector(length):\n",
        "  random_vector = tf.random.uniform(shape =(length,),minval=0,maxval=M, dtype=tf.dtypes.int32 ,seed=None,name=None)\n",
        "  random_hot_one_vector = tf.one_hot(random_vector, depth=M,on_value=1, off_value=0,axis=-1)\n",
        "  print(random_hot_one_vector.shape)\n",
        "  return random_hot_one_vector\n",
        "\n",
        "data, test_data = generate_data_vector(1000000), generate_data_vector(10000)\n",
        "#print(data)\n",
        "\n",
        "#model = Autoencoder()\n",
        "AE = get_AE(encoder, generator, decoder)\n",
        "AE.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history = AE.fit(data, data, batch_size=100,steps_per_epoch=1100, epochs=5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_24 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 2)                 32        \n",
            "_________________________________________________________________\n",
            "lambda_6 (Lambda)            (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 576\n",
            "Trainable params: 576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_3 (Lambda)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             multiple                  160       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             multiple                  1056      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             multiple                  64        \n",
            "=================================================================\n",
            "Total params: 1,280\n",
            "Trainable params: 1,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_27 (Dense)             (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 16)                48        \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 16)                256       \n",
            "=================================================================\n",
            "Total params: 310\n",
            "Trainable params: 310\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(1000000, 16)\n",
            "(10000, 16)\n",
            "Train on 1000000 samples\n",
            "Epoch 1/5\n",
            " 109200/1000000 [==>...........................] - ETA: 23s - loss: 1.8395 - accuracy: 0.2742Epoch 2/5\n",
            " 109000/1000000 [==>...........................] - ETA: 17s - loss: 0.9320 - accuracy: 0.6790Epoch 3/5\n",
            " 109100/1000000 [==>...........................] - ETA: 17s - loss: 0.4610 - accuracy: 0.8593Epoch 4/5\n",
            " 109100/1000000 [==>...........................] - ETA: 17s - loss: 0.2121 - accuracy: 0.9267Epoch 5/5\n",
            " 107900/1000000 [==>...........................] - ETA: 17s - loss: 0.1230 - accuracy: 0.9478"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ZsnSNgM7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_SNR_dB = 6\n",
        "\n",
        "def analytic_channel(input): \n",
        "  #print(input.shape)\n",
        "  return input + tf.random.normal(tf.shape(input), mean=0.0, stddev=noise_std)\n",
        "\n",
        "def real_transmision(test_data):\n",
        "  y = encoder(test_data)\n",
        "  y = generator(y)\n",
        "  y = decoder(y)\n",
        "  return y\n",
        "  #model = tf.keras.Sequential()\n",
        "  #model.add(encoder)\n",
        "  #model.add(tf.keras.layers.Lambda(generator))\n",
        "  #model.add(tf.keras.layers.Lambda(real_channel))\n",
        "  #model.add(decoder)\n",
        "  #return model\n",
        "\n",
        "def test_diff_eval(test_data, results):\n",
        "  diff = []\n",
        "  for i in range(tf.shape(test_data)[0]):\n",
        "    diff.append(tf.math.subtract(test_data[i,:], results[i,:]))\n",
        "  return diff\n",
        "    \n",
        "  \n",
        "real_AE = real_transmision(test_data)\n",
        "testTest = tf.dtypes.cast(real_AE + tf.constant(0.1,dtype=tf.float32,shape=tf.shape(real_AE)), tf.int32)\n",
        "\n",
        "diff_test =  test_diff_eval(test_data, testTest) \n",
        "#t = tf.math.subtract(test_data[1,:], real_AE[1,:])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntX-i_2J76v",
        "colab_type": "code",
        "outputId": "5d0d2bdc-89f4-4c93-84db-ddc0ed1ac1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(sum(diff_test))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([  0   0   0   0   0   0 594   0   0   0   0 611   0   0 613   0], shape=(16,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "outputId": "ee0ccb28-128a-4d9a-ed5a-b15dfa8e07fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= encoder.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAD8CAYAAAC/+/tYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDfTMdthneHM",
        "colab_type": "text"
      },
      "source": [
        "## Trainingparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIQ1bKE_nJSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_EbNodB = 6\n",
        "val_EbNodB = train_EbNodB\n",
        "\n",
        "training_params = [\n",
        "    #batch_size, lr, ebnodb, iterations\n",
        "    [100    , 0.001, train_EbNodB, 1000],\n",
        "    [100    , 0.0001, train_EbNodB, 10000],\n",
        "    [1000    , 0.0001, train_EbNodB, 10000]\n",
        "]\n",
        "\n",
        "validation_params = [\n",
        "    #batch_size, ebnodb, val_steps \n",
        "    [100000, val_EbNodB, 100],\n",
        "    [100000, val_EbNodB, 1000],\n",
        "    [100000, val_EbNodB, 1000]\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SR4RrE3nqTc",
        "colab_type": "text"
      },
      "source": [
        "## Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLzQO7yQnP1p",
        "colab_type": "code",
        "outputId": "cd484760-85f5-4641-8878-6d943f223767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "model_file_baseline = 'models/ae_baseline_k_{}_n_{}'.format(k,n)\n",
        "\n",
        "ae_baseline = AE(k,n,useGAN=False,seed=seed)\n",
        "ae_baseline.train(training_params, validation_params)\n",
        "\n",
        "ae_baseline.save(model_file_baseline)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a3cfbfeb8464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_file_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'models/ae_baseline_k_{}_n_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mae_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0museGAN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mae_baseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    850\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 851\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: call() got an unexpected keyword argument 'useGAN'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_IcVrbnS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}