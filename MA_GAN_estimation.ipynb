{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MA_GAN_estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/MA_GAN/blob/master/MA_GAN_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-49-RQG7bEV",
        "colab_type": "code",
        "outputId": "1a91b485-1e81-473c-d0dd-faf69b375530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-rc0\n",
        "!pip install -q pyyaml h5py\n",
        "#!pip install -q tf_nightly\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-rc0 in /usr/local/lib/python3.6/dist-packages (2.0.0rc0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.33.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.14.0.dev2019080601)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.16.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.0)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a20190807,>=1.15.0a20190806 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0a20190806)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0-rc0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-rc0) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (0.15.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9PJHQS0UCJ",
        "colab_type": "text"
      },
      "source": [
        "## System funktionsweise Allgemeine Daten\n",
        "\n",
        "#### Rauschen\n",
        "genarats-> **shape**: batch_size * number_of_real_channels_uses_per_message \\\\\n",
        "and does a average power normalization\n",
        "\n",
        "\n",
        "#### Generator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,n)   \\\\\n",
        "Loss-Function:\n",
        "\n",
        "#### Discriminator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,1)  \\\\\n",
        "Loss-Function:\n",
        "\n",
        "\n",
        "#### Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses **What is meant by that??** \\\\\n",
        "$N$ - L채nge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Y2r6qBAgKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 4       # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**k\n",
        "n = 2       # Number of real channel uses per message\n",
        "seed = 2    # Seed RNG reproduce identical results\n",
        "D_nb_weights = 32\n",
        "G_nb_weights = 32\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "x = tf.random.normal((batch_size,n))    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY9sHsfWT8By",
        "colab_type": "text"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "outputId": "ce411b99-23c4-45fc-ca04-af488f58c990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "\n",
        "#def generator(x):\n",
        "    # Concatenate z and y\n",
        "#    G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "#    inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "    #dense NN\n",
        "#    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
        "#    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "#    G_lin = tf.matmul(G_h2, G_W3) + G_b3\n",
        "    #G_prob = tf.nn.sigmoid(G_lin)\n",
        "#    return G_lin\n",
        "\n",
        "def generator_noise(input):\n",
        "  G_n = tf.random.normal([tf.shape(input)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "  inputs = tf.concat(values=[input, G_n], axis=1)\n",
        "  return inputs\n",
        "    \n",
        "def generator(x = tf.keras.Input(shape=(batch_size,n)),training = False):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Lambda(generator_noise))\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))#, input_shape=(2*n,))\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True,  activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=False, activation='sigmoid'))\n",
        "  return model\n",
        "\n",
        "generator= generator()\n",
        "test = generator(x)\n",
        "print(test[1])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0.4819897  0.49580827], shape=(2,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbjziKpv35v",
        "colab_type": "text"
      },
      "source": [
        "### Help Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rHD990Y-w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "#numpy version of kl divergence\n",
        "def kl_divergence_np(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w=1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return np.sum(p * np.log(p / q))\n",
        "\n",
        "#tensorflow version of kl divergence\n",
        "def kl_divergence_tf(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w = 1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return tf.reduce_sum(p * tf.log(p / q))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUzHiyUXLoP",
        "colab_type": "text"
      },
      "source": [
        "## Channels as Black-Box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63_fJJRXL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_SNR_dB = 6\n",
        "noise_std = EbNo2Sigma(train_SNR_dB)\n",
        "\n",
        "def real_channel(x):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzh-JZgfXSqN",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator\n",
        "Model definition and creating discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concc(y,x):  \n",
        "  inputs = tf.concat(values=[y,x], axis=1)\n",
        "  return inputs\n",
        "\n",
        "def get_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu',input_shape=((2*n,))))\n",
        "  model.add(tf.keras.layers.Dense(16,use_bias=True,  activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1,use_bias=False,activation='sigmoid'))\n",
        "  return model\n",
        "discriminator = get_discriminator()\n",
        "\n",
        "#def discriminator(y,x):\n",
        "#    # Concatenate x and y\n",
        "#    inputs = tf.concat(values=[y,x], axis=1)\n",
        "#    #dense NN\n",
        "#    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "#    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "#    D_prob = tf.nn.sigmoid(D_logit)\n",
        "#    return D_prob, D_logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnlfRYuYC8R",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation, 체berhaupt noch relevant??!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcnkBIUXYa_",
        "colab_type": "text"
      },
      "source": [
        "## discriminator desicion????\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7im8FYMXeOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xQt6M5Xd9P",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss\n",
        "strongly inspiered by: \\\\\n",
        "https://www.tensorflow.org/beta/tutorials/generative/dcgan?hl=en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36yIH7Q3FiEq",
        "colab_type": "text"
      },
      "source": [
        "## defining Loss. TODO:\n",
        "compile the Model with the right loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCLjUsVDzAn",
        "colab_type": "code",
        "outputId": "354fd5f1-7363-46f1-aa47-64c081e8b983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  \n",
        "fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=-1)\n",
        "\n",
        "print(real_training_data.shape,fake_training_data.shape)\n",
        "real_output = discriminator(real_training_data)\n",
        "fake_output = discriminator(fake_training_data)\n",
        "print(fake_output)\n",
        "#print(real_output, fake_output)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 4) (100, 4)\n",
            "tf.Tensor(\n",
            "[[0.54344714]\n",
            " [0.52413404]\n",
            " [0.5093189 ]\n",
            " [0.47057748]\n",
            " [0.49834082]\n",
            " [0.49357364]\n",
            " [0.47092938]\n",
            " [0.4735905 ]\n",
            " [0.5298665 ]\n",
            " [0.47384048]\n",
            " [0.5146605 ]\n",
            " [0.5057048 ]\n",
            " [0.4579929 ]\n",
            " [0.48269105]\n",
            " [0.46245638]\n",
            " [0.4708114 ]\n",
            " [0.4630347 ]\n",
            " [0.49307227]\n",
            " [0.48926246]\n",
            " [0.4943325 ]\n",
            " [0.4769314 ]\n",
            " [0.46299317]\n",
            " [0.506287  ]\n",
            " [0.57897127]\n",
            " [0.47680417]\n",
            " [0.45935446]\n",
            " [0.5330456 ]\n",
            " [0.4870076 ]\n",
            " [0.5180583 ]\n",
            " [0.46314695]\n",
            " [0.5981809 ]\n",
            " [0.50010836]\n",
            " [0.47111678]\n",
            " [0.4682378 ]\n",
            " [0.4780353 ]\n",
            " [0.48626384]\n",
            " [0.5098014 ]\n",
            " [0.46961588]\n",
            " [0.5168476 ]\n",
            " [0.44376442]\n",
            " [0.5450507 ]\n",
            " [0.4548832 ]\n",
            " [0.4559648 ]\n",
            " [0.5274183 ]\n",
            " [0.46578768]\n",
            " [0.49688193]\n",
            " [0.5207453 ]\n",
            " [0.6131379 ]\n",
            " [0.46158704]\n",
            " [0.5192825 ]\n",
            " [0.4781421 ]\n",
            " [0.4847735 ]\n",
            " [0.46610832]\n",
            " [0.44834983]\n",
            " [0.4232902 ]\n",
            " [0.51398677]\n",
            " [0.49661645]\n",
            " [0.55749094]\n",
            " [0.45519724]\n",
            " [0.52903694]\n",
            " [0.47296402]\n",
            " [0.4412995 ]\n",
            " [0.54145473]\n",
            " [0.53865755]\n",
            " [0.5749943 ]\n",
            " [0.5255321 ]\n",
            " [0.5322074 ]\n",
            " [0.46515125]\n",
            " [0.567675  ]\n",
            " [0.46513873]\n",
            " [0.6353698 ]\n",
            " [0.59388214]\n",
            " [0.53011084]\n",
            " [0.46739626]\n",
            " [0.54245335]\n",
            " [0.6528171 ]\n",
            " [0.5175411 ]\n",
            " [0.6009602 ]\n",
            " [0.61080664]\n",
            " [0.5600576 ]\n",
            " [0.4617211 ]\n",
            " [0.5170878 ]\n",
            " [0.4855219 ]\n",
            " [0.53461635]\n",
            " [0.50502545]\n",
            " [0.46633404]\n",
            " [0.46973437]\n",
            " [0.52818364]\n",
            " [0.44520566]\n",
            " [0.46795845]\n",
            " [0.55108505]\n",
            " [0.47607377]\n",
            " [0.45175838]\n",
            " [0.51813984]\n",
            " [0.45271748]\n",
            " [0.478011  ]\n",
            " [0.4831616 ]\n",
            " [0.47503757]\n",
            " [0.5126696 ]\n",
            " [0.46514654]], shape=(100, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERelQ5oTEMtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  loss= -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "  return loss\n",
        "  \n",
        "def generator_loss(fake_output, generator):\n",
        "  loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "  return loss\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gktABNcepz5c",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation with Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgM9lv-dp1PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_evaluation_data(batch_size=100):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "  #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "  #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "  fake_eval_data = tf.concat(values=[generator(x), x], axis=1)\n",
        "  real_eval_data = tf.concat(values=[real_channel(x), x], axis=1) #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "  inputs = x\n",
        "  return  real_eval_data, fake_eval_data, inputs \n",
        "\n",
        "\n",
        "\n",
        "def get_evaluation_data(evaluation_per_epochs):\n",
        "  real_eval_data = []\n",
        "  fake_eval_data  = []\n",
        "  inputs = []\n",
        "  for i in range(evaluation_per_epochs):\n",
        "    data = generate_evaluation_data()\n",
        "    real_eval_data.append(data[0])\n",
        "    fake_eval_data.append(data[1])\n",
        "    inputs.append(data[2])\n",
        "  return real_eval_data, fake_eval_data, inputs\n",
        "\n",
        "\n",
        "def test_eval(real_eval_data,fake_eval_data,inputs):\n",
        "  hist_range = 2\n",
        "  \n",
        "  inputs_ = tf.concat(values=[inputs, inputs],  axis=-1)\n",
        "  \n",
        "  fake_output_hist = np.mean(fake_eval_data,axis=1)  # Changed from 0 to 1\n",
        "  real_output_hist = np.mean(real_eval_data,axis=1)\n",
        "  inputs_hist = np.mean(inputs_,axis=1)\n",
        "    \n",
        "  fake_output_hist1 = np.reshape( fake_output_hist,[-1,])\n",
        "  real_output_hist1 = np.reshape( real_output_hist,[-1,])\n",
        "    \n",
        "  plt.hist(fake_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "  \n",
        "  fake_noise = np.reshape( fake_output_hist - inputs_hist,[-1,])\n",
        "  real_noise = np.reshape( real_output_hist - inputs_hist,[-1,])\n",
        "   \n",
        "  plt.hist(fake_noise,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_noise,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution after subtracting Inpus_noise\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "    \n",
        "    #print(\"decision for fake data was %d: and for real data was %d:\" % (decision_fake, decision_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQWOgXnl62o",
        "colab_type": "text"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sl75gEZl6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 25\n",
        "steps_per_epoches = 50\n",
        "batch_size = 100\n",
        "\n",
        "evaluation_per_epochs = 100\n",
        "\n",
        "noise_dim = n        #noch 채ndern wenn ich noise 채ndere\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooDukkHvmduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, steps_per_epoches , batch_size, generator, discriminator):\n",
        "  start = time.time()\n",
        "  counter = 0\n",
        "  epoch = 0\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    #print(massege_batch)\n",
        "    counter += 1\n",
        "    train_step(epoch, steps_per_epoches , batch_size, generator, discriminator) \n",
        "    if counter%5 == 0:\n",
        "      print(\"counter %d:\" % (counter))\n",
        "    if counter%5 == 0:\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "    print ('Time for epoch {} is {} sec,'.format(epoch + 1, time.time()-start))\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #print(x)\n",
        "    real_c = real_channel(x)\n",
        "    fake_c = generator(x)\n",
        "    if tf.math.is_nan(fake_c[1,1]) == True:\n",
        "      print(\"doesn't train the generator as expacted\")\n",
        "      tf.debugging.check_numerics(fake_c,'message',name=None)\n",
        "      break # in order to finde wher the [nan] - prolem is cumming from\n",
        "    \n",
        "       \n",
        "  #checkpoint_path = \"training_1/cp.ckpt\"\n",
        "  #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  #cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "  #                                               save_weights_only=False,\n",
        "  #                                               verbose=1)    \n",
        "  tf.saved_model.save(generator,'/tmp/saved_model/')\n",
        "  print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        "  print(gradients_of_generator)  \n",
        "  \n",
        "\n",
        "  # Generate after the final epoch\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7H98i7TmVxw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XxSryMYmCkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "#def train_step(massege_batch,counter):\n",
        "#    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "    #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "#    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "\n",
        "\n",
        " #   with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:           #tapes the gradient of the generaor an the discriminator\n",
        "  #    fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      \n",
        " #     real_output = discriminator(real_training_data, training=True)\n",
        " #     fake_output = discriminator(fake_training_data, training=True)\n",
        "\n",
        " #     disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        " #     gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        " #     gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        " #     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  #    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  #    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJno--QQh4_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "\n",
        "def train_step(epoch, steps_per_epoches , batch_size, generator, discriminator):\n",
        "\n",
        "    \n",
        "  for j in range(steps_per_epoches):\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      real_output = discriminator(real_training_data, training=True)\n",
        "      fake_output = discriminator(fake_training_data, training=True)\n",
        "      disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "      gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "      #print(disc_loss, gen_loss)\n",
        "          \n",
        "    \n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "      \n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGMDjc1metC",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82FQj3Jmvxx",
        "colab_type": "code",
        "outputId": "202c1be9-a2c6-4d2f-aefe-3fa4eb979483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "train(epochs, steps_per_epoches , batch_size, generator, discriminator)\n",
        "\n",
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Time for epoch 1 is 35.56552290916443 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Time for epoch 2 is 20.730703830718994 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Time for epoch 3 is 22.02608561515808 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Time for epoch 4 is 22.810688018798828 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "counter 5:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 5 is 34.23688817024231 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Time for epoch 6 is 23.984604597091675 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Time for epoch 7 is 21.177156448364258 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Time for epoch 8 is 24.219254732131958 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Time for epoch 9 is 20.60674738883972 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "counter 10:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4BYRCYyCW0QkMApuEZHAKLhFRALzP2eVpNDjgHZ0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 10 is 37.389392614364624 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Time for epoch 11 is 20.994774103164673 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_30:0\", shape=(), dtype=float32) Tensor(\"Neg_31:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_35:0\", shape=(), dtype=float32) Tensor(\"Neg_36:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_40:0\", shape=(), dtype=float32) Tensor(\"Neg_41:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_45:0\", shape=(), dtype=float32) Tensor(\"Neg_46:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_50:0\", shape=(), dtype=float32) Tensor(\"Neg_51:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_55:0\", shape=(), dtype=float32) Tensor(\"Neg_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_60:0\", shape=(), dtype=float32) Tensor(\"Neg_61:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_65:0\", shape=(), dtype=float32) Tensor(\"Neg_66:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_70:0\", shape=(), dtype=float32) Tensor(\"Neg_71:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_75:0\", shape=(), dtype=float32) Tensor(\"Neg_76:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_80:0\", shape=(), dtype=float32) Tensor(\"Neg_81:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_85:0\", shape=(), dtype=float32) Tensor(\"Neg_86:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_90:0\", shape=(), dtype=float32) Tensor(\"Neg_91:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_95:0\", shape=(), dtype=float32) Tensor(\"Neg_96:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_100:0\", shape=(), dtype=float32) Tensor(\"Neg_101:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_105:0\", shape=(), dtype=float32) Tensor(\"Neg_106:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_110:0\", shape=(), dtype=float32) Tensor(\"Neg_111:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_115:0\", shape=(), dtype=float32) Tensor(\"Neg_116:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_120:0\", shape=(), dtype=float32) Tensor(\"Neg_121:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_125:0\", shape=(), dtype=float32) Tensor(\"Neg_126:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_130:0\", shape=(), dtype=float32) Tensor(\"Neg_131:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_135:0\", shape=(), dtype=float32) Tensor(\"Neg_136:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_140:0\", shape=(), dtype=float32) Tensor(\"Neg_141:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_145:0\", shape=(), dtype=float32) Tensor(\"Neg_146:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_150:0\", shape=(), dtype=float32) Tensor(\"Neg_151:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_155:0\", shape=(), dtype=float32) Tensor(\"Neg_156:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_160:0\", shape=(), dtype=float32) Tensor(\"Neg_161:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_165:0\", shape=(), dtype=float32) Tensor(\"Neg_166:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_170:0\", shape=(), dtype=float32) Tensor(\"Neg_171:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_175:0\", shape=(), dtype=float32) Tensor(\"Neg_176:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_180:0\", shape=(), dtype=float32) Tensor(\"Neg_181:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_185:0\", shape=(), dtype=float32) Tensor(\"Neg_186:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_190:0\", shape=(), dtype=float32) Tensor(\"Neg_191:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_195:0\", shape=(), dtype=float32) Tensor(\"Neg_196:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_200:0\", shape=(), dtype=float32) Tensor(\"Neg_201:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_205:0\", shape=(), dtype=float32) Tensor(\"Neg_206:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_210:0\", shape=(), dtype=float32) Tensor(\"Neg_211:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_215:0\", shape=(), dtype=float32) Tensor(\"Neg_216:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_220:0\", shape=(), dtype=float32) Tensor(\"Neg_221:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_225:0\", shape=(), dtype=float32) Tensor(\"Neg_226:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_230:0\", shape=(), dtype=float32) Tensor(\"Neg_231:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_235:0\", shape=(), dtype=float32) Tensor(\"Neg_236:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_240:0\", shape=(), dtype=float32) Tensor(\"Neg_241:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_245:0\", shape=(), dtype=float32) Tensor(\"Neg_246:0\", shape=(), dtype=float32)\n",
            "Time for epoch 12 is 20.57533884048462 sec,\n",
            "Tensor(\"Neg:0\", shape=(), dtype=float32) Tensor(\"Neg_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_5:0\", shape=(), dtype=float32) Tensor(\"Neg_6:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_10:0\", shape=(), dtype=float32) Tensor(\"Neg_11:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_15:0\", shape=(), dtype=float32) Tensor(\"Neg_16:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_20:0\", shape=(), dtype=float32) Tensor(\"Neg_21:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Neg_25:0\", shape=(), dtype=float32) Tensor(\"Neg_26:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-1413dcdddf90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train(epochs, steps_per_epoches , batch_size, generator, discriminator)\\n\\ngenerator.summary()\\ndiscriminator.summary()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-6073cf335044>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, steps_per_epoches, batch_size, generator, discriminator)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#print(massege_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoches\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"counter %d:\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1819\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2148\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2036\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2038\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2039\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 ), args, kwargs)\n\u001b[0m\u001b[1;32m    903\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, options, args, kwargs, caller_fn_scope)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/tmppi4_j7ep.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(epoch, steps_per_epoches, batch_size, generator, discriminator)\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mtf__train_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_source_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag_source_map__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtf__train_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag_module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, init_vars, basic_symbol_names, composite_symbol_names)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_py_for_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\u001b[0m in \u001b[0;36m_py_for_stmt\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mextra_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/tmppi4_j7ep.py\u001b[0m in \u001b[0;36mloop_body\u001b[0;34m(iterates)\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mgradients_of_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradients_of_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradients_of_discriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, options, args, kwargs, caller_fn_scope)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0m_attach_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m       \u001b[0mapply_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m       return distribute_ctx.get_replica_context().merge_call(\n\u001b[1;32m    439\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_prepare\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0mapply_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/rmsprop.py\u001b[0m in \u001b[0;36m_prepare_local\u001b[0;34m(self, var_device, var_dtype, apply_state)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mone_minus_rho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     ))\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m   \u001b[0;31m# Propagate func.__doc__ to the wrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  11091\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11092\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m> 11093\u001b[0;31m         \"Sub\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m  11094\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11095\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    792\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    794\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    546\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    547\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0minput_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m     \u001b[0mcontrol_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_dependencies_for_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m     \u001b[0;31m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKRrixvwnA_m",
        "colab_type": "text"
      },
      "source": [
        "### Restore the latest checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw6Rt5z3Rjud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#print(x)\n",
        "real_c = real_channel(x)\n",
        "fake_c = generator(x)\n",
        "\n",
        "tf.debugging.check_numerics(fake_c,'message',name=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmP50TkiAg-C",
        "colab_type": "text"
      },
      "source": [
        "## AE\n",
        "Die Idee sollte sein das Training auf den encoder und decoder einzuschr채nken. Jedoch soll **end-to-end** trainiert werden, hierf체r sollte vllt eine art Funktion eingesetzt werden, welche 체ber die GAN's Layer zur체ck geht.\n",
        "Muss ich hierf체r die Layer nochmals einzeln definieren?\n",
        "\n",
        "\n",
        "***Vermutung: Der Ausgang hat die 8fache dimension des Eingangs-> daher nur 1/8 richtig oder 7/8 richtig*** \\\\\n",
        "**zu kl채ren: was passiert in meinem AE dass sie dei dimension ver8-facht von (1000,8) zu (8000,n)**\n",
        "**Kontrollieren was der output von meinem GAN ist**\n",
        "**Add complexity for higher rubustness**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def get_encoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[M]))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=False, activation=None))\n",
        "  model.add(tf.keras.layers.Lambda(lambda x : tf.divide(x, tf.sqrt(2*tf.reduce_mean(tf.square(x))))))\n",
        "  return model\n",
        "\n",
        "def get_decoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[n]))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=False, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "encoder = get_encoder()\n",
        "decoder = get_decoder()\n",
        "\n",
        "encoder.summary()\n",
        "generator.summary()\n",
        "decoder.summary()\n",
        "   \n",
        "def get_AE(encoder, generator, decoder):\n",
        "  AE_model = tf.keras.Sequential()\n",
        "  AE_model.add(encoder)\n",
        "  AE_model.add(tf.keras.layers.Lambda(generator))\n",
        "  AE_model.add(decoder)\n",
        "  return AE_model\n",
        "          \n",
        "    \n",
        "def generate_data_vector(length):\n",
        "  random_vector = tf.random.uniform(shape =(length,),minval=0,maxval=M, dtype=tf.dtypes.int32 ,seed=None,name=None)\n",
        "  random_hot_one_vector = tf.one_hot(random_vector, depth=M,on_value=1, off_value=0,axis=-1)\n",
        "  print(random_hot_one_vector.shape)\n",
        "  return random_hot_one_vector\n",
        "\n",
        "data, test_data = generate_data_vector(1000000), generate_data_vector(10000)\n",
        "#print(data)\n",
        "\n",
        "#model = Autoencoder()\n",
        "AE = get_AE(encoder, generator, decoder)\n",
        "AE.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history = AE.fit(data, data, batch_size=100,steps_per_epoch=3000, epochs=5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ZsnSNgM7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_SNR_dB = 6\n",
        "\n",
        "def analytic_channel(input): \n",
        "  #print(input.shape)\n",
        "  return input + tf.random.normal(tf.shape(input), mean=0.0, stddev=noise_std)\n",
        "\n",
        "def real_transmision(test_data):\n",
        "  y = encoder(test_data)\n",
        "  y = generator(y)\n",
        "  y = decoder(y)\n",
        "  return y\n",
        "  #model = tf.keras.Sequential()\n",
        "  #model.add(encoder)\n",
        "  #model.add(tf.keras.layers.Lambda(generator))\n",
        "  #model.add(tf.keras.layers.Lambda(real_channel))\n",
        "  #model.add(decoder)\n",
        "  #return model\n",
        "\n",
        "def test_diff_eval(test_data, results):\n",
        "  diff = []\n",
        "  for i in range(tf.shape(test_data)[0]):\n",
        "    diff.append(tf.math.subtract(test_data[i,:], results[i,:]))\n",
        "  return diff\n",
        "    \n",
        "  \n",
        "real_AE = real_transmision(test_data)\n",
        "testTest = tf.dtypes.cast(real_AE + tf.constant(0.1,dtype=tf.float32,shape=tf.shape(real_AE)), tf.int32)\n",
        "\n",
        "diff_test =  test_diff_eval(test_data, testTest) \n",
        "#t = tf.math.subtract(test_data[1,:], real_AE[1,:])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntX-i_2J76v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(sum(diff_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= encoder.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDfTMdthneHM",
        "colab_type": "text"
      },
      "source": [
        "## Trainingparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIQ1bKE_nJSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_EbNodB = 6\n",
        "val_EbNodB = train_EbNodB\n",
        "\n",
        "training_params = [\n",
        "    #batch_size, lr, ebnodb, iterations\n",
        "    [100    , 0.001, train_EbNodB, 1000],\n",
        "    [100    , 0.0001, train_EbNodB, 10000],\n",
        "    [1000    , 0.0001, train_EbNodB, 10000]\n",
        "]\n",
        "\n",
        "validation_params = [\n",
        "    #batch_size, ebnodb, val_steps \n",
        "    [100000, val_EbNodB, 100],\n",
        "    [100000, val_EbNodB, 1000],\n",
        "    [100000, val_EbNodB, 1000]\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SR4RrE3nqTc",
        "colab_type": "text"
      },
      "source": [
        "## Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLzQO7yQnP1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file_baseline = 'models/ae_baseline_k_{}_n_{}'.format(k,n)\n",
        "\n",
        "ae_baseline = AE(k,n,useGAN=False,seed=seed)\n",
        "ae_baseline.train(training_params, validation_params)\n",
        "\n",
        "ae_baseline.save(model_file_baseline)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_IcVrbnS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}