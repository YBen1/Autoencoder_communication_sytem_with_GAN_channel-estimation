{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MA_GAN_estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/MA_GAN/blob/master/Copy_of_MA_GAN_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-49-RQG7bEV",
        "colab_type": "code",
        "outputId": "18f6456d-92dc-4dfd-d84f-faeaf408b262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "!pip install tensorflow==2.0\n",
        "!pip install -q pyyaml h5py\n",
        "!pip install -q tf_nightly\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.16.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.1.7)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.33.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.7.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9PJHQS0UCJ",
        "colab_type": "text"
      },
      "source": [
        "## System funktionsweise Allgemeine Daten\n",
        "\n",
        "#### Rauschen\n",
        "genarats-> **shape**: batch_size * number_of_real_channels_uses_per_message \\\\\n",
        "and does a average power normalization\n",
        "\n",
        "\n",
        "#### Generator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,n)   \\\\\n",
        "Loss-Function:\n",
        "\n",
        "#### Discriminator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,1)  \\\\\n",
        "Loss-Function:\n",
        "\n",
        "\n",
        "#### Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses **What is meant by that??** \\\\\n",
        "$N$ - Länge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Y2r6qBAgKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 2       # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**k\n",
        "n = 4       # Number of real channel uses per message\n",
        "seed = 2    # Seed RNG reproduce identical results\n",
        "D_nb_weights = 32\n",
        "G_nb_weights = 32\n",
        "\n",
        "\n",
        "batch_size = 1000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = tf.random.normal((batch_size,n))    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "def make_zero(x):\n",
        "  return tf.keras.backend.zeros(shape=x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY9sHsfWT8By",
        "colab_type": "text"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "#numpy version of kl divergence\n",
        "def kl_divergence_np(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w=1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return np.sum(p * np.log(p / q))\n",
        "\n",
        "#tensorflow version of kl divergence\n",
        "def kl_divergence_tf(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w = 1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return tf.reduce_sum(p * tf.log(p / q))\n",
        "  \n",
        "  \n",
        "  \n",
        "train_SNR_dB = 7\n",
        "noise_std = EbNo2Sigma(train_SNR_dB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMMLrY0LthL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randN_initial = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "#zero_initial = tf.keras.initializers.Zeros()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "outputId": "d9dfe8bd-3e51-42b3-a2ba-d7fe72ce5258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "source": [
        "#\n",
        "\n",
        "#def generator(x):\n",
        "    # Concatenate z and y\n",
        "#    G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "#    inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "    #dense NN\n",
        "#    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
        "#    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "#    G_lin = tf.matmul(G_h2, G_W3) + G_b3\n",
        "    #G_prob = tf.nn.sigmoid(G_lin)\n",
        "#    return G_lin\n",
        "\n",
        "def generator_noise(x):\n",
        "  G_n = tf.random.normal([tf.shape(x)[0],n])  #create noise directly within the generator  \n",
        "  return G_n\n",
        "    \n",
        "tf.print(generator_noise(x).shape)\n",
        "\n",
        "#def get_generator(input = tf.keras.Input(shape=(batch_size,n)),training = False):\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.Lambda(generator_noise))\n",
        "#  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))#,input_shape=((2*n,))))\n",
        "#  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(n,use_bias=False, activation='sigmoid'))\n",
        "#  return model\n",
        "\n",
        "\n",
        "#input1 = tf.keras.layers.Input(shape=(n,))\n",
        "#x1 = tf.keras.layers.Dense(n, activation='relu')(input1)\n",
        "#input2 = tf.keras.layers.Input(shape=(n,)) #tf.keras.backend.zeros(shape=(n,))# Input(shape=(n,))\n",
        "#input3 = tf.keras.layers.GaussianNoise(noise_std)(input2) #input1,stddev =0.5\n",
        "#x2 = tf.keras.layers.Dense(n, activation='relu')(input3)\n",
        "#Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "#subtracted = tf.keras.layers.Concatenate(-1)([x1, x2])\n",
        "#h1 = tf.keras.layers.Dense(32)(subtracted)\n",
        "#h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "#out = tf.keras.layers.Dense(n, use_bias= False, activation='relu')(h2)\n",
        "\n",
        "#tf.reshape(input,(tf.shape(input)[0],-1))\n",
        "input1 = tf.keras.layers.Input(shape=(n,))\n",
        "x1 = tf.keras.layers.Dense(n)(input1)\n",
        "input2 =tf.random.normal([tf.shape(input1)[0],n]) \n",
        "x2 = tf.keras.layers.Dense(n)(input2)\n",
        "subtracted = tf.keras.layers.Concatenate(1)([x1, x2])\n",
        "h1 = tf.keras.layers.Dense(32,use_bias=True,  activation='relu')(subtracted)\n",
        "h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "out = tf.keras.layers.Dense(n, use_bias= True, activation='linear')(h2)\n",
        "\n",
        "#input2 = tf.keras.layers.Input(shape=(n,)) #tf.keras.backend.zeros(shape=(n,))# Input(shape=(n,))\n",
        "#input3 = tf.keras.layers.GaussianNoise(noise_std)(input2) #input1,stddev =0.5\n",
        "#x2 = tf.keras.layers.Dense(n, activation='relu')(input3)\n",
        "#Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#generator = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n",
        "generator = tf.keras.models.Model(inputs=[input1], outputs=out)\n",
        "generator.summary()\n",
        "#print(x.shape,(generator_noise(x)).shape)\n",
        "tf.print(generator([x]).shape)\n",
        "#test = generator(x)\n",
        "#print(test[1])\n",
        "generator.input\n",
        "#model.input"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 4])\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal/shape [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RandomStandardNorma [(None, 4)]          0           tf_op_layer_random_normal/shape[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_RandomStandardNormal[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal (Tens [(None, 4)]          0           tf_op_layer_mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            20          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            20          tf_op_layer_random_normal[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,516\n",
            "Trainable params: 1,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "TensorShape([1000, 4])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_1:0' shape=(None, 4) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbjziKpv35v",
        "colab_type": "text"
      },
      "source": [
        "### Help Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rHD990Y-w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUzHiyUXLoP",
        "colab_type": "text"
      },
      "source": [
        "## Channels as Black-Box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63_fJJRXL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def real_channel(x):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzh-JZgfXSqN",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator\n",
        "Model definition and creating discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "outputId": "4c1f5779-94bb-4b0f-e846-7aa53bfd5c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "def concc(y,x):  \n",
        "  inputs = tf.concat(values=[y,x], axis=1)\n",
        "  return inputs\n",
        "\n",
        "def get_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial,activation='relu',input_shape=((2*n,))))\n",
        "  #model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1,use_bias=False, activation='sigmoid'))\n",
        "  return model\n",
        "discriminator = get_discriminator()\n",
        "\n",
        "discriminator.summary()\n",
        "\n",
        "#def discriminator(y,x):\n",
        "#    # Concatenate x and y\n",
        "#    inputs = tf.concat(values=[y,x], axis=1)\n",
        "#    #dense NN\n",
        "#    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "#    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "#    D_prob = tf.nn.sigmoid(D_logit)\n",
        "#    return D_prob, D_logit"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 320\n",
            "Trainable params: 320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnlfRYuYC8R",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation, überhaupt noch relevant??!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcnkBIUXYa_",
        "colab_type": "text"
      },
      "source": [
        "## discriminator desicion????\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7im8FYMXeOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xQt6M5Xd9P",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss\n",
        "strongly inspiered by: \\\\\n",
        "https://www.tensorflow.org/beta/tutorials/generative/dcgan?hl=en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36yIH7Q3FiEq",
        "colab_type": "text"
      },
      "source": [
        "## defining Loss. TODO:\n",
        "compile the Model with the right loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCLjUsVDzAn",
        "colab_type": "code",
        "outputId": "45a317fa-7477-4e73-aa9d-4bbe4c8f9eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "real_training_data = tf.concat(values=[real_channel(x), x], axis=-1)  \n",
        "fake_training_data = tf.concat(values=[generator([x]),x], axis=-1)# training =True),x], axis=-1)\n",
        "\n",
        "tf.print(real_training_data.shape,fake_training_data.shape)\n",
        "real_output = discriminator(real_training_data)\n",
        "fake_output = discriminator(fake_training_data)\n",
        "tf.print(fake_output)\n",
        "tf.print(real_output)\n",
        "#print(real_output, fake_output)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 8]) TensorShape([1000, 8])\n",
            "[[0.515379727]\n",
            " [0.497625291]\n",
            " [0.485971093]\n",
            " ...\n",
            " [0.482796341]\n",
            " [0.513662934]\n",
            " [0.510382652]]\n",
            "[[0.524200559]\n",
            " [0.509041309]\n",
            " [0.461095631]\n",
            " ...\n",
            " [0.45032984]\n",
            " [0.514081657]\n",
            " [0.518964529]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERelQ5oTEMtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def discriminator_loss(real_output, fake_output):\n",
        "  #loss= -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "#  loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)  #Wasserstein GAN\n",
        "#  return loss\n",
        "\n",
        "def generator_loss(fake_output, generator):\n",
        "  return -tf.reduce_mean(fake_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCZBgwYBNYW",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8J9r3UpBNl1",
        "colab_type": "code",
        "outputId": "4e19062d-3418-4d79-959c-80b231f87d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)   #use \"-\" sign to minimize rather than maximize loss\n",
        "gen_loss =  -tf.reduce_mean(fake_output)\n",
        "#disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output)) #-tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "#gen_loss =-tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        "tf.print(disc_loss, gen_loss)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)      #RMSprop   in oreder to test where the error comes from\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)      #"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00566846132 -0.496548653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gktABNcepz5c",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation with Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgM9lv-dp1PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_evaluation_data(batch_size=1000):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "  #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "  #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "  fake_eval_data = tf.concat(values=[generator([x]), x], axis=1)\n",
        "  real_eval_data = tf.concat(values=[real_channel(x), x], axis=1) #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "  inputs = x\n",
        "  return  real_eval_data, fake_eval_data, inputs \n",
        "\n",
        "\n",
        "\n",
        "def get_evaluation_data(evaluation_per_epochs):\n",
        "  real_eval_data = []\n",
        "  fake_eval_data  = []\n",
        "  inputs = []\n",
        "  for i in range(evaluation_per_epochs):\n",
        "    data = generate_evaluation_data()\n",
        "    real_eval_data.append(data[0])\n",
        "    fake_eval_data.append(data[1])\n",
        "    inputs.append(data[2])\n",
        "  return real_eval_data, fake_eval_data, inputs\n",
        "\n",
        "\n",
        "def test_eval(real_eval_data,fake_eval_data,inputs):\n",
        "  hist_range = 3\n",
        "  \n",
        "  #inputs_ = tf.concat(values=[inputs, inputs],  axis=0)\n",
        "  \n",
        "  fake_output_hist = np.mean(fake_eval_data,axis=0)  # Changed from 0 to 1\n",
        "  real_output_hist = np.mean(real_eval_data,axis=0)\n",
        "  inputs_hist = np.mean(inputs,axis=0)\n",
        "    \n",
        "  fake_output_hist1 = np.reshape( fake_output_hist,[-1,])\n",
        "  real_output_hist1 = np.reshape( real_output_hist,[-1,])\n",
        "    \n",
        "  plt.hist(fake_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "  tf.print(inputs_hist.shape)\n",
        "  \n",
        "  #fake_noise = np.reshape( fake_output_hist - inputs_hist,[-1,])\n",
        "  #real_noise = np.reshape( real_output_hist - inputs_hist,[-1,])\n",
        "   \n",
        "  #plt.hist(fake_noise,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  #plt.hist(real_noise,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  #plt.title(\"noise distribution after subtracting Inpus_noise\")\n",
        "  #plt.legend([\"generator\", \"target\"])\n",
        "  #plt.show()\n",
        "    \n",
        "    #print(\"decision for fake data was %d: and for real data was %d:\" % (decision_fake, decision_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQWOgXnl62o",
        "colab_type": "text"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sl75gEZl6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 2000\n",
        "steps_per_epoches = 100\n",
        "batch_size = 1000\n",
        "\n",
        "evaluation_per_epochs = 10\n",
        "\n",
        "seed = tf.random.normal([batch_size, n])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZUTZng_fFBk",
        "colab_type": "text"
      },
      "source": [
        "# Wasserstein clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEFEdt29fEj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clip_D = [p.assign(tf.clip_by_value(p, -0.001, 0.001)) for p in discriminator.trainable_variables]\n",
        "\n",
        "#def get_disc_grad(trainable_variables):\n",
        "#  return [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in trainable_variables]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooDukkHvmduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, steps_per_epoches , batch_size):\n",
        "  start = time.time()\n",
        "  counter = 0\n",
        "  epoch = 0\n",
        "  for epoch in range(epochs):\n",
        "    #print(massege_batch)\n",
        "    counter += 1\n",
        "\n",
        "    \n",
        "    train_step() \n",
        "    #tf.print(generator_optimizer.apply_gradients())\n",
        "    #if counter%5 == 0:\n",
        "    if counter%100==0:\n",
        "      tf.print(\"counter %d:\" % (counter))\n",
        "      fake_c = generator([x,generator_noise(x)])\n",
        "      tf.print(fake_c[0])\n",
        "    if counter%6 == 0 and counter<8:\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "    if counter%1000 == 0:\n",
        "      real_c = real_channel(x)\n",
        "      fake_c = generator([x,generator_noise(x)])\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "      tf.print(fake_c[0])\n",
        "      tf.print(disc_loss, gen_loss)\n",
        "    #print ('Time for epoch {} is {} sec,'.format(epoch + 1, time.time()-start))\n",
        "      tf.print ('Time for epoch {},'.format(epoch + 1))\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #print(x)\n",
        "    fake_c = generator([x,generator_noise(x)])\n",
        "    if tf.math.is_nan(fake_c[0,0]) == True:\n",
        "      print(\"doesn't train the generator as expacted\")\n",
        "      tf.debugging.check_numerics(fake_c,'message generator',name=None)\n",
        "      break # in order to finde wher the [nan] - prolem is cumming from\n",
        "    \n",
        "       \n",
        "  #checkpoint_path = \"training_1/cp.ckpt\"\n",
        "  #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  #cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "  #                                               save_weights_only=False,\n",
        "  #                                               verbose=1)    \n",
        "  tf.saved_model.save(generator,'/tmp/saved_model/')\n",
        "  tf.print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        " # print(gradients_of_generator)  \n",
        "  \n",
        "\n",
        "  # Generate after the final epoch\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7H98i7TmVxw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XxSryMYmCkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "#def train_step(massege_batch,counter):\n",
        "#    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "    #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "#    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "\n",
        "\n",
        " #   with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:           #tapes the gradient of the generaor an the discriminator\n",
        "  #    fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      \n",
        " #     real_output = discriminator(real_training_data, training=True)\n",
        " #     fake_output = discriminator(fake_training_data, training=True)\n",
        "\n",
        " #     disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        " #     gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        " #     gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        " #     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  #    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  #    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJno--QQh4_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(): #epoch, steps_per_epoches , batch_size, generator, discriminator):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "  for i in range(5):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      real_training_data = tf.concat(values=[real_channel(x), x], axis=1)\n",
        "      fake_training_data = tf.concat(values=[generator(x),x], axis=1)# training =True),x], axis=1)\n",
        "      real_output = discriminator(real_training_data)#, training=True)\n",
        "      fake_output = discriminator(fake_training_data)\n",
        "      \n",
        "      \n",
        "      #disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)  #use \"-\" sign to minimize rather than maximize loss\n",
        "      #gen_loss =  -tf.reduce_mean(fake_output)\n",
        "      #tf.print(real_training_data.shape, real_output[1].shape)\n",
        "      #tf.debugging.check_numerics(disc_loss,'loss generator',name=None)\n",
        "      # clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in gradients_of_discriminator]   \n",
        "      #tf.print(real_training_data[0])\n",
        "      \n",
        "      disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output)) #-tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "      gen_loss =-tf.reduce_mean(tf.math.log(fake_output))\n",
        "      #disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)   #use \"-\" sign to minimize rather than maximize loss\n",
        "      #gen_loss =  -tf.reduce_mean(fake_output)\n",
        "      #tf.print(disc_loss, gen_loss)\n",
        "      if tf.math.is_nan(disc_loss) == False:\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "        #tf.print(disc_loss, gen_loss)\n",
        "      if i == 4:  \n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "        #tf.print(disc_loss, gen_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGMDjc1metC",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82FQj3Jmvxx",
        "colab_type": "code",
        "outputId": "f185ad7c-e116-476e-e9a9-680e561f8f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "train(epochs, steps_per_epoches , batch_size)\n",
        "print(generator(x)[1])\n",
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "counter 100:\n",
            "[0.409376502 0.0779451355 -0.218001947 0.00584981032]\n",
            "counter 200:\n",
            "[0.0877447575 -0.0216076747 0.322706908 0.00701296702]\n",
            "counter 300:\n",
            "[0.0173389446 -0.202022076 0.421284497 -0.0196524635]\n",
            "counter 400:\n",
            "[-0.479946 0.0501507968 0.509133935 -0.786945343]\n",
            "counter 500:\n",
            "[0.527614772 -0.158740371 -0.219843045 0.0959883]\n",
            "counter 600:\n",
            "[-0.664025486 0.0396701358 0.766239583 0.00738299452]\n",
            "counter 700:\n",
            "[0.164232507 -0.128229961 -0.294801265 0.0190531313]\n",
            "counter 800:\n",
            "[0.112276644 0.167939171 -0.0796450749 0.00512382574]\n",
            "counter 900:\n",
            "[-0.164905518 -0.247763455 -0.0881322 -0.0411648527]\n",
            "counter 1000:\n",
            "[-0.974405348 0.10806147 -0.0923854783 -0.504839957]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "[-0.798137 0.236118346 -0.282699138 -0.373467684]\n",
            "0.00566846132 -0.496548653\n",
            "Time for epoch 1000,\n",
            "counter 1100:\n",
            "[0.729244411 -0.570586562 0.923973083 0.342846066]\n",
            "counter 1200:\n",
            "[0.14575918 -0.188403562 0.340553612 -0.473066419]\n",
            "counter 1300:\n",
            "[-0.91009587 1.00860167 -1.45189679 0.133555025]\n",
            "counter 1400:\n",
            "[0.281279862 0.243374914 0.476772189 -0.111747801]\n",
            "counter 1500:\n",
            "[-0.420549542 -1.36024606 -0.200190336 0.602635205]\n",
            "counter 1600:\n",
            "[-0.448305607 -1.2592144 0.457310289 -1.14205813]\n",
            "counter 1700:\n",
            "[-0.805437326 -0.977112114 -0.706568837 -0.208622411]\n",
            "counter 1800:\n",
            "[-0.0162423849 1.13762534 0.939080298 0.752039492]\n",
            "counter 1900:\n",
            "[0.709488 -0.981202066 0.201112285 0.372386336]\n",
            "counter 2000:\n",
            "[-0.0382804684 0.349683553 0.836297452 0.821278334]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nr0bwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "[-0.0900934339 0.276778847 0.875912 0.749631047]\n",
            "0.00566846132 -0.496548653\n",
            "Time for epoch 2000,\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /tmp/saved_model/assets\n",
            "Time for the training is 107.58166933059692 sec,\n",
            "tf.Tensor([-0.6963804  -0.5377303  -0.8952184   0.26847664], shape=(4,), dtype=float32)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal/shape [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RandomStandardNorma [(None, 4)]          0           tf_op_layer_random_normal/shape[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_RandomStandardNormal[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal (Tens [(None, 4)]          0           tf_op_layer_mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            20          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            20          tf_op_layer_random_normal[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,516\n",
            "Trainable params: 1,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 320\n",
            "Trainable params: 320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 2min 3s, sys: 4.34 s, total: 2min 7s\n",
            "Wall time: 1min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw6Rt5z3Rjud",
        "colab_type": "code",
        "outputId": "466ca8c0-e89f-4c8d-a2c5-a40ab132b332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#print(x)\n",
        "real_c = real_channel(x)\n",
        "fake_c = generator([x])\n",
        "tf.print(real_c.shape)\n",
        "tf.print(fake_c.shape)\n",
        "\n",
        "#tf.debugging.check_numerics(fake_c,'message',name=None)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 4])\n",
            "TensorShape([1000, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmP50TkiAg-C",
        "colab_type": "text"
      },
      "source": [
        "## AE\n",
        "Die Idee sollte sein das Training auf den encoder und decoder einzuschränken. Jedoch soll **end-to-end** trainiert werden, hierfür sollte vllt eine art Funktion eingesetzt werden, welche über die GAN's Layer zurück geht.\n",
        "Muss ich hierfür die Layer nochmals einzeln definieren?\n",
        "\n",
        "\n",
        "***Vermutung: Der Ausgang hat die 8fache dimension des Eingangs-> daher nur 1/8 richtig oder 7/8 richtig*** \\\\\n",
        "**zu klären: was passiert in meinem AE dass sie dei dimension ver8-facht von (1000,8) zu (8000,n)**\n",
        "**Kontrollieren was der output von meinem GAN ist**\n",
        "**Add complexity for higher rubustness**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "outputId": "c7bac0bb-1d88-476c-9c16-def6c579a1fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "def B_Ber(input_msg, msg):\n",
        "    '''Calculate the Batch Bit Error Rate'''\n",
        "    pred_error = tf.not_equal(tf.argmax(msg, 1), tf.argmax(input_msg, 1))\n",
        "    bber = tf.reduce_mean(tf.cast(pred_error, tf.float32))\n",
        "    return bber\n",
        "\n",
        "\n",
        "#def get_encoder():\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.InputLayer(input_shape=[M]))\n",
        "#  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='elu'))\n",
        "  #model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(n,use_bias=False, activation=None))\n",
        "#  model.add(tf.keras.layers.Lambda(lambda x : tf.divide(x, tf.sqrt(2*tf.reduce_mean(tf.square(x))))))\n",
        "#  return model\n",
        "\n",
        "#def get_decoder():\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.InputLayer(input_shape=[n]))\n",
        "#  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='elu'))\n",
        "  #model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(M,use_bias=False, activation='softmax'))\n",
        "#  return model\n",
        "\n",
        "#encoder = get_encoder()\n",
        "#decoder = get_decoder()\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "#def test_Model(x):\n",
        "#  y = encoder(x)\n",
        "#  y = generator([y,make_zero(y)])\n",
        "#  y = decoder(y)\n",
        "#  return y\n",
        "  \n",
        "#****************************************************  From  Rick Fritschek \"Communication-via-Autoencoder-TF2\"\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "gen_shape_layer = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))\n",
        "#gen_shape_layer = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))\n",
        "gen_shape_layer2 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))\n",
        "\n",
        "\n",
        "def weight_variable(M):\n",
        "  low = np.sqrt(6.0/(2*M)) \n",
        "  high = -np.sqrt(6.0/(2*M))\n",
        "  return tf.random.uniform((M,M), minval=low, maxval=high, dtype=tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "def encoder(input):\n",
        "  '''The transmitter'''\n",
        "  W = weight_variable(M)    \n",
        "  x = tf.nn.elu(tf.nn.embedding_lookup(W, input))\n",
        "  x = tf.keras.layers.Dense(n, activation=None)(x)\n",
        "  x = tf.reshape(x, shape=[-1,int(n/2),2])\n",
        "  #Average power normalization\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) \n",
        "  return x\n",
        "\n",
        "\n",
        "bla =encoder([1,2,2,1])            #ecoder: (4, 2, 2)\n",
        "blaa =tf.reshape(x,(tf.shape(x)[0],-1))\n",
        "blaaa = generator(blaa)\n",
        "blaaaa = tf.reshape(blaaa, shape=[-1,int(n/2),2])\n",
        "blaaaaa = decoder(blaaa)\n",
        "\n",
        "print(bla.shape)\n",
        "print(blaa.shape)\n",
        "print(blaaa.shape)\n",
        "print(blaaaa.shape)\n",
        "print(blaaaaa.shape)\n",
        "\n",
        "\n",
        "\n",
        "def decoder(input):\n",
        "  '''The Receiver'''\n",
        "  y = tf.reshape(input, shape=[-1,n])\n",
        "  y = tf.keras.layers.Dense(M, activation='relu')(y)\n",
        "  y = tf.keras.layers.Dense(M, activation=None)(y)\n",
        "  return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#encoder = keras.models.Sequential([\n",
        "#tf.keras.layers.InputLayer(input_shape=[M]),\n",
        "#tf.keras.layers.Dense(M, activation=\"relu\"),\n",
        "#tf.keras.layers.Dense(2*n, activation=None),\n",
        "#shape_layer,\n",
        "#norm_layer])\n",
        "\n",
        "\n",
        "\n",
        "#channel = keras.models.Sequential([channel_layer])\n",
        "\n",
        "#decoder = keras.models.Sequential([tf.keras.layers.InputLayer(input_shape=[2,n]),\n",
        "#shape_layer2,\n",
        "#tf.keras.layers.Dense(M, activation=\"relu\"),\n",
        "#tf.keras.layers.Dense(M, activation=\"softmax\")\n",
        "#])  \n",
        "  \n",
        "#encoder.summary()\n",
        "#generator.summary()\n",
        "#decoder.summary() \n",
        "\n",
        "\n",
        "\n",
        "def get_AE():\n",
        "  AE_model = tf.keras.Sequential()\n",
        "  AE_model.add(tf.keras.layers.Lambda(encoder))\n",
        "  AE_model.add(gen_shape_layer)\n",
        "  AE_model.add(tf.keras.layers.Lambda(generator))\n",
        "  AE_model.add(gen_shape_layer2)\n",
        "  AE_model.add(tf.keras.layers.Lambda(decoder))\n",
        "  return AE_model\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "def generate_data_vector(length):\n",
        "  random_vector = tf.random.uniform(shape =(length,),minval=0,maxval=M, dtype=tf.dtypes.int32 ,seed=None,name=None)\n",
        "  random_hot_one_vector = tf.one_hot(random_vector, depth=M,on_value=1, off_value=0,axis=-1)\n",
        "  tf.print(random_hot_one_vector.shape)\n",
        "  return random_hot_one_vector\n",
        "\n",
        "data, test_data = generate_data_vector(10000000), generate_data_vector(10000)\n",
        "#print(data)\n",
        "\n",
        "#model = Autoencoder()\n",
        "AE = get_AE()\n",
        "AE.compile(optimizer='adam',loss='categorical_crossentropy',metrics=[B_Ber])\n",
        "#history = AE.fit(data, data, batch_size=1000,steps_per_epoch=1000, epochs=6)\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 2, 2)\n",
            "(1000, 4)\n",
            "(1000, 4)\n",
            "(1000, 2, 2)\n",
            "(1000, 4)\n",
            "TensorShape([10000000, 4])\n",
            "TensorShape([10000, 4])\n",
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2b8d71158811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m \u001b[0mAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[0;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2469\u001b[0;31m       \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_steps_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_steps_argument\u001b[0;34m(input_data, steps, steps_name)\u001b[0m\n\u001b[1;32m   1201\u001b[0m       raise ValueError('When using {input_type} as input to a model, you should'\n\u001b[1;32m   1202\u001b[0m                        ' specify the `{steps_name}` argument.'.format(\n\u001b[0;32m-> 1203\u001b[0;31m                            input_type=input_type_str, steps_name=steps_name))\n\u001b[0m\u001b[1;32m   1204\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ZsnSNgM7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def analytic_channel(input): \n",
        "  #print(input.shape)\n",
        "  return input + tf.random.normal(tf.shape(input), mean=0.0, stddev=noise_std)\n",
        "\n",
        "def real_transmision(test_data):\n",
        "  y = encoder(test_data)\n",
        "  y = generator(y)\n",
        "  y = decoder(y)\n",
        "  return y\n",
        "  #model = tf.keras.Sequential()\n",
        "  #model.add(encoder)\n",
        "  #model.add(tf.keras.layers.Lambda(generator))\n",
        "  #model.add(tf.keras.layers.Lambda(real_channel))\n",
        "  #model.add(decoder)\n",
        "  #return model\n",
        "\n",
        "def test_diff_eval(test_data, results):\n",
        "  diff = []\n",
        "  for i in range(tf.shape(test_data)[0]):\n",
        "    diff.append(tf.math.subtract(test_data[i,:], results[i,:]))\n",
        "  return diff\n",
        "    \n",
        "  \n",
        "real_AE = real_transmision(test_data)\n",
        "testTest = tf.dtypes.cast(real_AE + tf.constant(0.1,dtype=tf.float32,shape=tf.shape(real_AE)), tf.int32)\n",
        "\n",
        "diff_test =  test_diff_eval(test_data, testTest) \n",
        "#t = tf.math.subtract(test_data[1,:], real_AE[1,:])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntX-i_2J76v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.print(sum(diff_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= encoder.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8o3nqP_0OTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= AE.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SR4RrE3nqTc",
        "colab_type": "text"
      },
      "source": [
        "## Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_IcVrbnS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}