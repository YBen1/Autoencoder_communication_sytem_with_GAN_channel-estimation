{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MA_GAN_estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/MA_GAN/blob/master/Copy_of_MA_GAN_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-49-RQG7bEV",
        "colab_type": "code",
        "outputId": "0f69af81-81a9-4018-94d4-844c337f88a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0rc2\n",
        "#!pip install -q pyyaml h5py\n",
        "#!pip install -q tf_nightly\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0rc2\n",
            "  Using cached https://files.pythonhosted.org/packages/46/b2/0a8f6f62cdd91c7d727efc717f339265ace99b36847f2bda7a9f2897cfee/tensorflow-2.0.0rc2-cp36-cp36m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (2.0.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.14.0.dev2019080601)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (3.7.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (3.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (0.33.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.16.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0rc2) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0rc2) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0rc2) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0rc2) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0rc2) (2.8.0)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.0.0rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9PJHQS0UCJ",
        "colab_type": "text"
      },
      "source": [
        "## System funktionsweise Allgemeine Daten\n",
        "\n",
        "#### Rauschen\n",
        "genarats-> **shape**: batch_size * number_of_real_channels_uses_per_message \\\\\n",
        "and does a average power normalization\n",
        "\n",
        "\n",
        "#### Generator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,n)   \\\\\n",
        "Loss-Function:\n",
        "\n",
        "#### Discriminator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,1)  \\\\\n",
        "Loss-Function:\n",
        "\n",
        "\n",
        "#### Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses **What is meant by that??** \\\\\n",
        "$N$ - Länge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Y2r6qBAgKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 2       # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**k\n",
        "n = 4       # Number of real channel uses per message\n",
        "seed = 2    # Seed RNG reproduce identical results\n",
        "D_nb_weights = 32\n",
        "G_nb_weights = 32\n",
        "\n",
        "\n",
        "batch_size = 1000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = tf.random.normal((batch_size,n))    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "def make_zero(x):\n",
        "  return tf.keras.backend.zeros(shape=x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY9sHsfWT8By",
        "colab_type": "text"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "#numpy version of kl divergence\n",
        "def kl_divergence_np(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w=1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return np.sum(p * np.log(p / q))\n",
        "\n",
        "#tensorflow version of kl divergence\n",
        "def kl_divergence_tf(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w = 1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return tf.reduce_sum(p * tf.log(p / q))\n",
        "  \n",
        "  \n",
        "  \n",
        "train_SNR_dB = 7\n",
        "noise_std = EbNo2Sigma(train_SNR_dB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMMLrY0LthL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randN_initial = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "#zero_initial = tf.keras.initializers.Zeros()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "outputId": "ceaf55f2-62fd-46cb-c2da-5787723756e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "source": [
        "#\n",
        "\n",
        "#def generator(x):\n",
        "    # Concatenate z and y\n",
        "#    G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "#    inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "    #dense NN\n",
        "#    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
        "#    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "#    G_lin = tf.matmul(G_h2, G_W3) + G_b3\n",
        "    #G_prob = tf.nn.sigmoid(G_lin)\n",
        "#    return G_lin\n",
        "\n",
        "def generator_noise(x):\n",
        "  G_n = tf.random.normal([tf.shape(x)[0],n])  #create noise directly within the generator  \n",
        "  return G_n\n",
        "    \n",
        "tf.print(generator_noise(x).shape)\n",
        "\n",
        "#def get_generator(input = tf.keras.Input(shape=(batch_size,n)),training = False):\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.Lambda(generator_noise))\n",
        "#  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))#,input_shape=((2*n,))))\n",
        "#  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(n,use_bias=False, activation='sigmoid'))\n",
        "#  return model\n",
        "\n",
        "\n",
        "#input1 = tf.keras.layers.Input(shape=(n,))\n",
        "#x1 = tf.keras.layers.Dense(n, activation='relu')(input1)\n",
        "#input2 = tf.keras.layers.Input(shape=(n,)) #tf.keras.backend.zeros(shape=(n,))# Input(shape=(n,))\n",
        "#input3 = tf.keras.layers.GaussianNoise(noise_std)(input2) #input1,stddev =0.5\n",
        "#x2 = tf.keras.layers.Dense(n, activation='relu')(input3)\n",
        "#Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "#subtracted = tf.keras.layers.Concatenate(-1)([x1, x2])\n",
        "#h1 = tf.keras.layers.Dense(32)(subtracted)\n",
        "#h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "#out = tf.keras.layers.Dense(n, use_bias= False, activation='relu')(h2)\n",
        "\n",
        "#tf.reshape(input,(tf.shape(input)[0],-1))\n",
        "input1 = tf.keras.layers.Input(shape=(n,))\n",
        "x1 = tf.keras.layers.Dense(n)(input1)\n",
        "input2 =tf.random.normal([tf.shape(input1)[0],n]) \n",
        "x2 = tf.keras.layers.Dense(n)(input2)\n",
        "subtracted = tf.keras.layers.Concatenate(1)([x1, x2])\n",
        "h1 = tf.keras.layers.Dense(32,use_bias=True,  activation='relu')(subtracted)\n",
        "h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "out = tf.keras.layers.Dense(n, use_bias= True, activation='linear')(h2)\n",
        "\n",
        "#input2 = tf.keras.layers.Input(shape=(n,)) #tf.keras.backend.zeros(shape=(n,))# Input(shape=(n,))\n",
        "#input3 = tf.keras.layers.GaussianNoise(noise_std)(input2) #input1,stddev =0.5\n",
        "#x2 = tf.keras.layers.Dense(n, activation='relu')(input3)\n",
        "#Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#generator = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n",
        "generator = tf.keras.models.Model(inputs=[input1], outputs=out)\n",
        "generator.summary()\n",
        "#print(x.shape,(generator_noise(x)).shape)\n",
        "tf.print(generator([x]).shape)\n",
        "#test = generator(x)\n",
        "#print(test[1])\n",
        "generator.input\n",
        "#model.input"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 4])\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal/shape [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RandomStandardNorma [(None, 4)]          0           tf_op_layer_random_normal/shape[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_RandomStandardNormal[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal (Tens [(None, 4)]          0           tf_op_layer_mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            20          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            20          tf_op_layer_random_normal[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,516\n",
            "Trainable params: 1,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "TensorShape([1000, 4])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_1:0' shape=(None, 4) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbjziKpv35v",
        "colab_type": "text"
      },
      "source": [
        "### Help Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rHD990Y-w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUzHiyUXLoP",
        "colab_type": "text"
      },
      "source": [
        "## Channels as Black-Box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63_fJJRXL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def real_channel(x):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzh-JZgfXSqN",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator\n",
        "Model definition and creating discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "outputId": "7b17b962-4215-4e21-d243-df09567ff90a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "def concc(y,x):  \n",
        "  inputs = tf.concat(values=[y,x], axis=1)\n",
        "  return inputs\n",
        "\n",
        "def get_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial,activation='relu',input_shape=((2*n,))))\n",
        "  #model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1,use_bias=False, activation='sigmoid'))\n",
        "  return model\n",
        "discriminator = get_discriminator()\n",
        "\n",
        "discriminator.summary()\n",
        "\n",
        "#def discriminator(y,x):\n",
        "#    # Concatenate x and y\n",
        "#    inputs = tf.concat(values=[y,x], axis=1)\n",
        "#    #dense NN\n",
        "#    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "#    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "#    D_prob = tf.nn.sigmoid(D_logit)\n",
        "#    return D_prob, D_logit"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 320\n",
            "Trainable params: 320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnlfRYuYC8R",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation, überhaupt noch relevant??!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcnkBIUXYa_",
        "colab_type": "text"
      },
      "source": [
        "## discriminator desicion????\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7im8FYMXeOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xQt6M5Xd9P",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss\n",
        "strongly inspiered by: \\\\\n",
        "https://www.tensorflow.org/beta/tutorials/generative/dcgan?hl=en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36yIH7Q3FiEq",
        "colab_type": "text"
      },
      "source": [
        "## defining Loss. TODO:\n",
        "compile the Model with the right loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCLjUsVDzAn",
        "colab_type": "code",
        "outputId": "b8fd0492-d6a0-4add-8718-ec2258930f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "real_training_data = tf.concat(values=[real_channel(x), x], axis=-1)  \n",
        "fake_training_data = tf.concat(values=[generator([x]),x], axis=-1)# training =True),x], axis=-1)\n",
        "\n",
        "tf.print(real_training_data.shape,fake_training_data.shape)\n",
        "real_output = discriminator(real_training_data)\n",
        "fake_output = discriminator(fake_training_data)\n",
        "tf.print(fake_output)\n",
        "tf.print(real_output)\n",
        "#print(real_output, fake_output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 8]) TensorShape([1000, 8])\n",
            "[[0.495548904]\n",
            " [0.494939983]\n",
            " [0.487576902]\n",
            " ...\n",
            " [0.49256435]\n",
            " [0.506556869]\n",
            " [0.50652045]]\n",
            "[[0.516591847]\n",
            " [0.530786157]\n",
            " [0.490795642]\n",
            " ...\n",
            " [0.503625929]\n",
            " [0.458086193]\n",
            " [0.503744185]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERelQ5oTEMtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def discriminator_loss(real_output, fake_output):\n",
        "  #loss= -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "#  loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)  #Wasserstein GAN\n",
        "#  return loss\n",
        "\n",
        "def generator_loss(fake_output, generator):\n",
        "  return -tf.reduce_mean(fake_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCZBgwYBNYW",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8J9r3UpBNl1",
        "colab_type": "code",
        "outputId": "d24c8319-59ff-484a-84c9-72a61cfac92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)   #use \"-\" sign to minimize rather than maximize loss\n",
        "gen_loss =  -tf.reduce_mean(fake_output)\n",
        "#disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output)) #-tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "#gen_loss =-tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        "tf.print(disc_loss, gen_loss)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)      #RMSprop   in oreder to test where the error comes from\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)      #"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00106364489 -0.494426847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gktABNcepz5c",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation with Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgM9lv-dp1PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_evaluation_data(batch_size=1000):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "  #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "  #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "  fake_eval_data = tf.concat(values=[generator([x]), x], axis=1)\n",
        "  real_eval_data = tf.concat(values=[real_channel(x), x], axis=1) #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "  inputs = x\n",
        "  return  real_eval_data, fake_eval_data, inputs \n",
        "\n",
        "\n",
        "\n",
        "def get_evaluation_data(evaluation_per_epochs):\n",
        "  real_eval_data = []\n",
        "  fake_eval_data  = []\n",
        "  inputs = []\n",
        "  for i in range(evaluation_per_epochs):\n",
        "    data = generate_evaluation_data()\n",
        "    real_eval_data.append(data[0])\n",
        "    fake_eval_data.append(data[1])\n",
        "    inputs.append(data[2])\n",
        "  return real_eval_data, fake_eval_data, inputs\n",
        "\n",
        "\n",
        "def test_eval(real_eval_data,fake_eval_data,inputs):\n",
        "  hist_range = 3\n",
        "  \n",
        "  #inputs_ = tf.concat(values=[inputs, inputs],  axis=0)\n",
        "  \n",
        "  fake_output_hist = np.mean(fake_eval_data,axis=0)  # Changed from 0 to 1\n",
        "  real_output_hist = np.mean(real_eval_data,axis=0)\n",
        "  inputs_hist = np.mean(inputs,axis=0)\n",
        "    \n",
        "  fake_output_hist1 = np.reshape( fake_output_hist,[-1,])\n",
        "  real_output_hist1 = np.reshape( real_output_hist,[-1,])\n",
        "    \n",
        "  plt.hist(fake_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_output_hist1,bins=100,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "  tf.print(inputs_hist.shape)\n",
        "  \n",
        "  #fake_noise = np.reshape( fake_output_hist - inputs_hist,[-1,])\n",
        "  #real_noise = np.reshape( real_output_hist - inputs_hist,[-1,])\n",
        "   \n",
        "  #plt.hist(fake_noise,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  #plt.hist(real_noise,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  #plt.title(\"noise distribution after subtracting Inpus_noise\")\n",
        "  #plt.legend([\"generator\", \"target\"])\n",
        "  #plt.show()\n",
        "    \n",
        "    #print(\"decision for fake data was %d: and for real data was %d:\" % (decision_fake, decision_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQWOgXnl62o",
        "colab_type": "text"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sl75gEZl6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 2000\n",
        "steps_per_epoches = 100\n",
        "batch_size = 1000\n",
        "\n",
        "evaluation_per_epochs = 10\n",
        "\n",
        "seed = tf.random.normal([batch_size, n])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZUTZng_fFBk",
        "colab_type": "text"
      },
      "source": [
        "# Wasserstein clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEFEdt29fEj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clip_D = [p.assign(tf.clip_by_value(p, -0.001, 0.001)) for p in discriminator.trainable_variables]\n",
        "\n",
        "#def get_disc_grad(trainable_variables):\n",
        "#  return [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in trainable_variables]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooDukkHvmduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, steps_per_epoches , batch_size):\n",
        "  start = time.time()\n",
        "  counter = 0\n",
        "  epoch = 0\n",
        "  for epoch in range(epochs):\n",
        "    #print(massege_batch)\n",
        "    counter += 1\n",
        "\n",
        "    \n",
        "    train_step() \n",
        "    #tf.print(generator_optimizer.apply_gradients())\n",
        "    #if counter%5 == 0:\n",
        "    if counter%100==0:\n",
        "      tf.print(\"counter %d:\" % (counter))\n",
        "      fake_c = generator([x,generator_noise(x)])\n",
        "      tf.print(fake_c[0])\n",
        "    if counter%6 == 0 and counter<8:\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "    if counter%1000 == 0:\n",
        "      real_c = real_channel(x)\n",
        "      fake_c = generator([x,generator_noise(x)])\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "      tf.print(fake_c[0])\n",
        "      tf.print(disc_loss, gen_loss)\n",
        "    #print ('Time for epoch {} is {} sec,'.format(epoch + 1, time.time()-start))\n",
        "      tf.print ('Time for epoch {},'.format(epoch + 1))\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #print(x)\n",
        "    fake_c = generator([x,generator_noise(x)])\n",
        "    if tf.math.is_nan(fake_c[0,0]) == True:\n",
        "      print(\"doesn't train the generator as expacted\")\n",
        "      tf.debugging.check_numerics(fake_c,'message generator',name=None)\n",
        "      break # in order to finde wher the [nan] - prolem is cumming from\n",
        "    \n",
        "       \n",
        "  #checkpoint_path = \"training_1/cp.ckpt\"\n",
        "  #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  #cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "  #                                               save_weights_only=False,\n",
        "  #                                               verbose=1)    \n",
        "  tf.saved_model.save(generator,'/tmp/saved_model/')\n",
        "  tf.print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        " # print(gradients_of_generator)  \n",
        "  \n",
        "\n",
        "  # Generate after the final epoch\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7H98i7TmVxw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XxSryMYmCkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "#def train_step(massege_batch,counter):\n",
        "#    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "    #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "#    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "\n",
        "\n",
        " #   with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:           #tapes the gradient of the generaor an the discriminator\n",
        "  #    fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      \n",
        " #     real_output = discriminator(real_training_data, training=True)\n",
        " #     fake_output = discriminator(fake_training_data, training=True)\n",
        "\n",
        " #     disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        " #     gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        " #     gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        " #     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  #    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  #    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJno--QQh4_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(): #epoch, steps_per_epoches , batch_size, generator, discriminator):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "  for i in range(5):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      real_training_data = tf.concat(values=[real_channel(x), x], axis=1)\n",
        "      fake_training_data = tf.concat(values=[generator(x),x], axis=1)# training =True),x], axis=1)\n",
        "      real_output = discriminator(real_training_data)#, training=True)\n",
        "      fake_output = discriminator(fake_training_data)\n",
        "      \n",
        "      \n",
        "      #disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)  #use \"-\" sign to minimize rather than maximize loss\n",
        "      #gen_loss =  -tf.reduce_mean(fake_output)\n",
        "      #tf.print(real_training_data.shape, real_output[1].shape)\n",
        "      #tf.debugging.check_numerics(disc_loss,'loss generator',name=None)\n",
        "      # clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in gradients_of_discriminator]   \n",
        "      #tf.print(real_training_data[0])\n",
        "      \n",
        "      disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output)) #-tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "      gen_loss =-tf.reduce_mean(tf.math.log(fake_output))\n",
        "      #disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)   #use \"-\" sign to minimize rather than maximize loss\n",
        "      #gen_loss =  -tf.reduce_mean(fake_output)\n",
        "      #tf.print(disc_loss, gen_loss)\n",
        "      if tf.math.is_nan(disc_loss) == False:\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "        #tf.print(disc_loss, gen_loss)\n",
        "      if i == 4:  \n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "        #tf.print(disc_loss, gen_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGMDjc1metC",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82FQj3Jmvxx",
        "colab_type": "code",
        "outputId": "5328ca15-2fcf-4c2d-f12a-1abd095a2bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "train(epochs, steps_per_epoches , batch_size)\n",
        "print(generator(x)[1])\n",
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxUP62azYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "counter 100:\n",
            "[0.695254803 -0.117476314 0.00339130405 0.480147451]\n",
            "counter 200:\n",
            "[0.0953111947 -0.330191284 -0.221802354 -0.131656989]\n",
            "counter 300:\n",
            "[-0.406550676 -0.135615245 0.218698591 -0.06739299]\n",
            "counter 400:\n",
            "[-0.260532081 0.153131306 -0.0523516685 0.0530016907]\n",
            "counter 500:\n",
            "[0.301829785 -0.795693159 0.625965595 0.550819099]\n",
            "counter 600:\n",
            "[0.258168429 -0.712454 0.00277994247 -0.423574984]\n",
            "counter 700:\n",
            "[-0.337060064 0.301970899 -0.205628067 -0.720262289]\n",
            "counter 800:\n",
            "[-0.0121632265 0.25493139 0.142879486 -0.331622124]\n",
            "counter 900:\n",
            "[0.203526184 0.416532218 -1.46986771 1.17589903]\n",
            "counter 1000:\n",
            "[-1.05808103 0.920227528 -0.204109505 -0.61342448]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "[0.0156454928 0.349244475 -0.155790314 -0.856909275]\n",
            "0.00106364489 -0.494426847\n",
            "Time for epoch 1000,\n",
            "counter 1100:\n",
            "[0.480582833 1.04332483 0.56907028 0.0474329665]\n",
            "counter 1200:\n",
            "[-0.173024267 0.688510299 0.466544718 -0.89406538]\n",
            "counter 1300:\n",
            "[-0.211620033 -0.0798177719 0.403482586 -0.936527]\n",
            "counter 1400:\n",
            "[-0.164042458 -0.840667605 0.00366452336 -0.0390043408]\n",
            "counter 1500:\n",
            "[-1.61765027 -0.109590448 0.379620582 -0.736064076]\n",
            "counter 1600:\n",
            "[0.632680774 0.313120812 -0.99520421 -0.649045825]\n",
            "counter 1700:\n",
            "[-0.384256542 -0.268873692 0.530815065 0.255724221]\n",
            "counter 1800:\n",
            "[-0.107434049 -1.03198493 -0.186376095 -0.451193422]\n",
            "counter 1900:\n",
            "[-0.325075775 0.921895921 -1.53130126 -1.05554879]\n",
            "counter 2000:\n",
            "[0.282649904 -0.946329474 0.986231387 -0.096155934]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "[-0.109815642 -0.888151705 0.893469334 -0.12715444]\n",
            "0.00106364489 -0.494426847\n",
            "Time for epoch 2000,\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /tmp/saved_model/assets\n",
            "Time for the training is 103.43600177764893 sec,\n",
            "tf.Tensor([-0.1266843  0.4362536  1.1032234 -0.8043564], shape=(4,), dtype=float32)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal/shape [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RandomStandardNorma [(None, 4)]          0           tf_op_layer_random_normal/shape[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_RandomStandardNormal[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal (Tens [(None, 4)]          0           tf_op_layer_mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            20          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            20          tf_op_layer_random_normal[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,516\n",
            "Trainable params: 1,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 320\n",
            "Trainable params: 320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 1min 59s, sys: 4.22 s, total: 2min 3s\n",
            "Wall time: 1min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw6Rt5z3Rjud",
        "colab_type": "code",
        "outputId": "7117a5c2-ff08-44c4-d1b8-f35068ba3b9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#print(x)\n",
        "real_c = real_channel(x)\n",
        "fake_c = generator([x])\n",
        "tf.print(real_c.shape)\n",
        "tf.print(fake_c.shape)\n",
        "\n",
        "#tf.debugging.check_numerics(fake_c,'message',name=None)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 4])\n",
            "TensorShape([1000, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmP50TkiAg-C",
        "colab_type": "text"
      },
      "source": [
        "## AE\n",
        "Die Idee sollte sein das Training auf den encoder und decoder einzuschränken. Jedoch soll **end-to-end** trainiert werden, hierfür sollte vllt eine art Funktion eingesetzt werden, welche über die GAN's Layer zurück geht.\n",
        "Muss ich hierfür die Layer nochmals einzeln definieren?\n",
        "\n",
        "\n",
        "***Vermutung: Der Ausgang hat die 8fache dimension des Eingangs-> daher nur 1/8 richtig oder 7/8 richtig*** \\\\\n",
        "**zu klären: was passiert in meinem AE dass sie dei dimension ver8-facht von (1000,8) zu (8000,n)**\n",
        "**Kontrollieren was der output von meinem GAN ist**\n",
        "**Add complexity for higher rubustness**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "outputId": "a6afcc7e-9212-4f70-eb94-62bf5ea4ebed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def B_Ber(input_msg, msg):\n",
        "    '''Calculate the Batch Bit Error Rate'''\n",
        "    pred_error = tf.not_equal(tf.argmax(msg, 1), tf.argmax(input_msg, 1))\n",
        "    bber = tf.reduce_mean(tf.cast(pred_error, tf.float32))\n",
        "    return bber\n",
        "\n",
        "\n",
        "#def get_encoder():\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.InputLayer(input_shape=[M]))\n",
        "#  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='elu'))\n",
        "  #model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(n,use_bias=False, activation=None))\n",
        "#  model.add(tf.keras.layers.Lambda(lambda x : tf.divide(x, tf.sqrt(2*tf.reduce_mean(tf.square(x))))))\n",
        "#  return model\n",
        "\n",
        "#def get_decoder():\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.InputLayer(input_shape=[n]))\n",
        "#  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='elu'))\n",
        "  #model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(M,use_bias=False, activation='softmax'))\n",
        "#  return model\n",
        "\n",
        "#encoder = get_encoder()\n",
        "#decoder = get_decoder()\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "#def test_Model(x):\n",
        "#  y = encoder(x)\n",
        "#  y = generator([y,make_zero(y)])\n",
        "#  y = decoder(y)\n",
        "#  return y\n",
        "  \n",
        "#****************************************************  From  Rick Fritschek \"Communication-via-Autoencoder-TF2\"\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "gen_shape_layer = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))\n",
        "#gen_shape_layer = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))\n",
        "gen_shape_layer2 = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def decoder(input):\n",
        "  '''The Receiver'''\n",
        "  y = tf.reshape(input, shape=[-1,n])\n",
        "  y = tf.keras.layers.Dense(M, activation='relu')(y)\n",
        "  y = tf.keras.layers.Dense(M, activation=None)(y)\n",
        "  return y\n",
        "\n",
        "\n",
        "\n",
        "def encoder(input):\n",
        "  '''The transmitter'''\n",
        "  low = np.sqrt(6.0/(2*M)) \n",
        "  high = -np.sqrt(6.0/(2*M))\n",
        "  W =tf.random.uniform((M,M), minval=low, maxval=high, dtype=tf.float32)    \n",
        "  x = tf.nn.elu(tf.nn.embedding_lookup(W, input))\n",
        "  x = tf.keras.layers.Dense(n, activation=None)(x)\n",
        "  x = tf.reshape(x, shape=[-1,int(n/2),2])\n",
        "  #Average power normalization\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) \n",
        "  return x\n",
        "\n",
        "bl = generate_data_vector(1000)\n",
        "bla =encoder(bl)            #ecoder: (4, 2, 2)\n",
        "blaa =tf.reshape(x,(tf.shape(x)[0],-1))\n",
        "blaaa = generator(blaa)\n",
        "blaaaa = tf.reshape(blaaa, shape=[-1,int(n/2),2])\n",
        "blaaaaa = decoder(blaaa)\n",
        "\n",
        "print('encoder input',bl.dtype)\n",
        "print('encoder output',bla.dtype)\n",
        "print('reshaped generator input',blaa.shape)\n",
        "print('generator output',blaaa.shape)\n",
        "print('reshaped generator output',blaaaa.shape)\n",
        "print('decoder output',blaaaaa.shape)\n",
        "\n",
        "\n",
        "EncIn = tf.keras.layers.Input(shape=(n,), dtype= tf.int32)\n",
        "EncOut = tf.keras.layers.Lambda(encoder)(EncIn)\n",
        "GenIn = tf.keras.layers.Lambda(lambda x:tf.reshape(x,(tf.shape(x)[0],-1)))(EncOut)\n",
        "GenOut = tf.keras.layers.Lambda(generator)(GenIn)\n",
        "DecIn = tf.keras.layers.Lambda(lambda x:tf.reshape(x, shape=[-1,int(n/2),2]))(GenOut)\n",
        "out = tf.keras.layers.Lambda(decoder)(DecIn)\n",
        "\n",
        "\n",
        "\n",
        "AE = tf.keras.models.Model(inputs=EncIn, outputs=out)\n",
        "AE.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#encoder = keras.models.Sequential([\n",
        "#tf.keras.layers.InputLayer(input_shape=[M]),\n",
        "#tf.keras.layers.Dense(M, activation=\"relu\"),\n",
        "#tf.keras.layers.Dense(2*n, activation=None),\n",
        "#shape_layer,\n",
        "#norm_layer])\n",
        "\n",
        "\n",
        "\n",
        "#channel = keras.models.Sequential([channel_layer])\n",
        "\n",
        "#decoder = keras.models.Sequential([tf.keras.layers.InputLayer(input_shape=[2,n]),\n",
        "#shape_layer2,\n",
        "#tf.keras.layers.Dense(M, activation=\"relu\"),\n",
        "#tf.keras.layers.Dense(M, activation=\"softmax\")\n",
        "#])  \n",
        "  \n",
        "#encoder.summary()\n",
        "#generator.summary()\n",
        "#decoder.summary() \n",
        "\n",
        "\n",
        "\n",
        "#def get_AE():\n",
        "#  AE_model = tf.keras.Sequential()\n",
        "#  AE_model.add(tf.keras.layers.Lambda(encoder))\n",
        "#  AE_model.add(gen_shape_layer)\n",
        "#  AE_model.add(tf.keras.layers.Lambda(generator))\n",
        "#  AE_model.add(gen_shape_layer2)\n",
        "#  AE_model.add(tf.keras.layers.Lambda(decoder))\n",
        " # return AE_model\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "def generate_data_vector(length):\n",
        "  random_vector = tf.random.uniform(shape =(length,),minval=0,maxval=M, dtype=tf.dtypes.int32 ,seed=None,name=None)\n",
        "  random_hot_one_vector = tf.one_hot(random_vector, depth=M,on_value=1, off_value=0,axis=-1)\n",
        "  tf.print(random_hot_one_vector.shape)\n",
        "  return random_hot_one_vector\n",
        "\n",
        "data, test_data = generate_data_vector(10000000), generate_data_vector(10000)\n",
        "#print(data)\n",
        "\n",
        "#model = Autoencoder()\n",
        "#AE = get_AE()\n",
        "AE.compile(optimizer='adam',loss='categorical_crossentropy',metrics=[B_Ber])\n",
        "history = AE.fit(data, data, batch_size=1000,steps_per_epoch=1000, epochs=6)\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 4])\n",
            "encoder input <dtype: 'int32'>\n",
            "encoder output <dtype: 'float32'>\n",
            "reshaped generator input (1000, 4)\n",
            "generator output (1000, 4)\n",
            "reshaped generator output (1000, 2, 2)\n",
            "decoder output (1000, 4)\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 4)]               0         \n",
            "_________________________________________________________________\n",
            "lambda_51 (Lambda)           (None, 2, 2)              20        \n",
            "_________________________________________________________________\n",
            "lambda_52 (Lambda)           (None, None)              0         \n",
            "_________________________________________________________________\n",
            "lambda_53 (Lambda)           (None, 4)                 1516      \n",
            "_________________________________________________________________\n",
            "lambda_54 (Lambda)           (None, 2, 2)              0         \n",
            "_________________________________________________________________\n",
            "lambda_55 (Lambda)           (None, 4)                 20        \n",
            "=================================================================\n",
            "Total params: 1,556\n",
            "Trainable params: 1,556\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TensorShape([10000000, 4])\n",
            "TensorShape([10000, 4])\n",
            "Train on 10000000 samples\n",
            "Epoch 1/6\n",
            "    1000/10000000 [..............................] - ETA: 31:51"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 1000 and 4000 for 'loss/lambda_55_loss/mul' (op: 'Mul') with input shapes: [1000,4], [4000,4].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-ed42a860aa5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;31m#AE = get_AE()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB_Ber\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reduction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m           \u001b[0mper_sample_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m           weighted_losses = losses_utils.compute_weighted_loss(\n\u001b[1;32m    168\u001b[0m               \u001b[0mper_sample_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    219\u001b[0m       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n\u001b[1;32m    220\u001b[0m           y_pred, y_true)\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing)\u001b[0m\n\u001b[1;32m    969\u001b[0m   y_true = smart_cond.smart_cond(label_smoothing,\n\u001b[1;32m    970\u001b[0m                                  _smooth_labels, lambda: y_true)\n\u001b[0;32m--> 971\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4466\u001b[0m       \u001b[0mepsilon_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constant_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4467\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepsilon_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4468\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4469\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4470\u001b[0m       \u001b[0;31m# When softmax activation function is used for output operation, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1204\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6699\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6700\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 6701\u001b[0;31m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   6702\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6703\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    792\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    794\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    546\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    547\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3427\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3429\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1771\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1772\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1773\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1774\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1611\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1613\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 1000 and 4000 for 'loss/lambda_55_loss/mul' (op: 'Mul') with input shapes: [1000,4], [4000,4]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ZsnSNgM7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def analytic_channel(input): \n",
        "  #print(input.shape)\n",
        "  return input + tf.random.normal(tf.shape(input), mean=0.0, stddev=noise_std)\n",
        "\n",
        "def real_transmision(test_data):\n",
        "  y = encoder(test_data)\n",
        "  y = generator(y)\n",
        "  y = decoder(y)\n",
        "  return y\n",
        "  #model = tf.keras.Sequential()\n",
        "  #model.add(encoder)\n",
        "  #model.add(tf.keras.layers.Lambda(generator))\n",
        "  #model.add(tf.keras.layers.Lambda(real_channel))\n",
        "  #model.add(decoder)\n",
        "  #return model\n",
        "\n",
        "def test_diff_eval(test_data, results):\n",
        "  diff = []\n",
        "  for i in range(tf.shape(test_data)[0]):\n",
        "    diff.append(tf.math.subtract(test_data[i,:], results[i,:]))\n",
        "  return diff\n",
        "    \n",
        "  \n",
        "real_AE = real_transmision(test_data)\n",
        "testTest = tf.dtypes.cast(real_AE + tf.constant(0.1,dtype=tf.float32,shape=tf.shape(real_AE)), tf.int32)\n",
        "\n",
        "diff_test =  test_diff_eval(test_data, testTest) \n",
        "#t = tf.math.subtract(test_data[1,:], real_AE[1,:])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntX-i_2J76v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.print(sum(diff_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= encoder.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8o3nqP_0OTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= AE.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SR4RrE3nqTc",
        "colab_type": "text"
      },
      "source": [
        "## Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_IcVrbnS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}