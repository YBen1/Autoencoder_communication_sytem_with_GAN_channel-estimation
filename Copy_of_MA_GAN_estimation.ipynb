{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MA_GAN_estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenYavor/MA_GAN/blob/master/Copy_of_MA_GAN_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-49-RQG7bEV",
        "colab_type": "code",
        "outputId": "9707532a-6444-40ae-fbab-f4aab39fc9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "!pip install tensorflow==2.0\n",
        "!pip install -q pyyaml h5py\n",
        "!pip install -q tf_nightly\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt   \n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
        "    import tensorflow as tf\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
        "tf.__version__\n",
        "from tensorflow import keras\n",
        "import time\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.16.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.1.7)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (2.0.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.7.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.33.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.0.8)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9PJHQS0UCJ",
        "colab_type": "text"
      },
      "source": [
        "## System funktionsweise Allgemeine Daten\n",
        "\n",
        "#### Rauschen\n",
        "genarats-> **shape**: batch_size * number_of_real_channels_uses_per_message \\\\\n",
        "and does a average power normalization\n",
        "\n",
        "\n",
        "#### Generator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,n)   \\\\\n",
        "Loss-Function:\n",
        "\n",
        "#### Discriminator\n",
        "Eingang: (2*n,32)  ; Ausgang: (32,1)  \\\\\n",
        "Loss-Function:\n",
        "\n",
        "\n",
        "#### Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qpY-gawAf-9",
        "colab_type": "text"
      },
      "source": [
        "###Systemparameter\n",
        "$k$ - die Anzhal der bits \\\\\n",
        "$M$ - Anzahl der unterschiedlichen Nachrichten \\\\\n",
        "$n$ - channel uses **What is meant by that??** \\\\\n",
        "$N$ - Länge des Rauschvektors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Y2r6qBAgKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 2       # Number of information bits per message, i.e., M=2**k\n",
        "M = 2**k\n",
        "n = 4       # Number of real channel uses per message\n",
        "seed = 2    # Seed RNG reproduce identical results\n",
        "D_nb_weights = 32\n",
        "G_nb_weights = 32\n",
        "\n",
        "\n",
        "batch_size = 1000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = tf.random.normal((batch_size,n))    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "def make_zero(x):\n",
        "  return tf.keras.backend.zeros(shape=x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY9sHsfWT8By",
        "colab_type": "text"
      },
      "source": [
        "## Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV7pjryDv4M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EbNo2Sigma(ebnodb):\n",
        "    '''Convert Eb/No in dB to noise standard deviation'''\n",
        "    ebno = 10**(ebnodb/10)\n",
        "    return 1/np.sqrt(2*(2*k/n)*ebno)\n",
        "\n",
        "#numpy version of kl divergence\n",
        "def kl_divergence_np(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w=1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return np.sum(p * np.log(p / q))\n",
        "\n",
        "#tensorflow version of kl divergence\n",
        "def kl_divergence_tf(p, q):\n",
        "    #use \"Laplace correction\" w to avoid zero and inf\n",
        "    w = 1e-5\n",
        "    p = p + w\n",
        "    q = q + w\n",
        "    return tf.reduce_sum(p * tf.log(p / q))\n",
        "  \n",
        "  \n",
        "  \n",
        "train_SNR_dB = 7\n",
        "noise_std = EbNo2Sigma(train_SNR_dB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMMLrY0LthL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randN_initial = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
        "#zero_initial = tf.keras.initializers.Zeros()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXbS5lM9Tb9B",
        "colab_type": "code",
        "outputId": "2972919c-cc72-47b2-b17f-1d1bf350093b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        }
      },
      "source": [
        "#\n",
        "\n",
        "#def generator(x):\n",
        "    # Concatenate z and y\n",
        "#    G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32)  #create noise directly within the generator  \n",
        "#    inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "    #dense NN\n",
        "#    G_h1 = tf.nn.relu(tf.matmul(inputs, G_W1) + G_b1)\n",
        "#    G_h2 = tf.nn.relu(tf.matmul(G_h1, G_W2) + G_b2)\n",
        "#    G_lin = tf.matmul(G_h2, G_W3) + G_b3\n",
        "    #G_prob = tf.nn.sigmoid(G_lin)\n",
        "#    return G_lin\n",
        "\n",
        "def generator_noise(x):\n",
        "  G_n = tf.random.normal([tf.shape(x)[0],n])  #create noise directly within the generator  \n",
        "  return G_n\n",
        "    \n",
        "tf.print(generator_noise(x).shape)\n",
        "\n",
        "#def get_generator(input = tf.keras.Input(shape=(batch_size,n)),training = False):\n",
        "#  model = tf.keras.Sequential()\n",
        "#  model.add(tf.keras.layers.Lambda(generator_noise))\n",
        "#  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))#,input_shape=((2*n,))))\n",
        "#  model.add(tf.keras.layers.Dense(32,use_bias=True, activation='relu'))\n",
        "#  model.add(tf.keras.layers.Dense(n,use_bias=False, activation='sigmoid'))\n",
        "#  return model\n",
        "\n",
        "\n",
        "#input1 = tf.keras.layers.Input(shape=(n,))\n",
        "#x1 = tf.keras.layers.Dense(n, activation='relu')(input1)\n",
        "#input2 = tf.keras.layers.Input(shape=(n,)) #tf.keras.backend.zeros(shape=(n,))# Input(shape=(n,))\n",
        "#input3 = tf.keras.layers.GaussianNoise(noise_std)(input2) #input1,stddev =0.5\n",
        "#x2 = tf.keras.layers.Dense(n, activation='relu')(input3)\n",
        "#Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "#subtracted = tf.keras.layers.Concatenate(-1)([x1, x2])\n",
        "#h1 = tf.keras.layers.Dense(32)(subtracted)\n",
        "#h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "#out = tf.keras.layers.Dense(n, use_bias= False, activation='relu')(h2)\n",
        "\n",
        "input1 = tf.keras.layers.Input(shape=(n,))\n",
        "x1 = tf.keras.layers.Dense(n)(input1)\n",
        "input2 =tf.random.normal([tf.shape(input1)[0],n]) \n",
        "x2 = tf.keras.layers.Dense(n)(input2)\n",
        "subtracted = tf.keras.layers.Concatenate(1)([x1, x2])\n",
        "h1 = tf.keras.layers.Dense(32,use_bias=True,  activation='relu')(subtracted)\n",
        "h2 = tf.keras.layers.Dense(32,use_bias=True, activation='relu')(h1)\n",
        "out = tf.keras.layers.Dense(n, use_bias= True, activation='linear')(h2)\n",
        "\n",
        "#input2 = tf.keras.layers.Input(shape=(n,)) #tf.keras.backend.zeros(shape=(n,))# Input(shape=(n,))\n",
        "#input3 = tf.keras.layers.GaussianNoise(noise_std)(input2) #input1,stddev =0.5\n",
        "#x2 = tf.keras.layers.Dense(n, activation='relu')(input3)\n",
        "#Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#generator = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n",
        "generator = tf.keras.models.Model(inputs=[input1], outputs=out)\n",
        "generator.summary()\n",
        "#print(x.shape,(generator_noise(x)).shape)\n",
        "tf.print(generator([x]).shape)\n",
        "#test = generator(x)\n",
        "#print(test[1])\n",
        "generator.input\n",
        "#model.input"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 4])\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal/shape [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RandomStandardNorma [(None, 4)]          0           tf_op_layer_random_normal/shape[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_RandomStandardNormal[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal (Tens [(None, 4)]          0           tf_op_layer_mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            20          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            20          tf_op_layer_random_normal[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,516\n",
            "Trainable params: 1,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "TensorShape([1000, 4])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_1:0' shape=(None, 4) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbjziKpv35v",
        "colab_type": "text"
      },
      "source": [
        "### Help Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rHD990Y-w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EUzHiyUXLoP",
        "colab_type": "text"
      },
      "source": [
        "## Channels as Black-Box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W63_fJJRXL7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def real_channel(x):\n",
        "    # Black-box Channel\n",
        "    #AWGN\n",
        "    return x + tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std)\n",
        "\n",
        "    #Rayleigh\n",
        "    #return x + tf.sqrt(tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)) + tf.square(tf.random_normal(tf.shape(x), mean=0.0, stddev=noise_std)))\n",
        "    \n",
        "    #Uniform U(-3;3)    \n",
        "    #return x + tf.random_uniform(tf.shape(x), minval=-2, maxval=2)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzh-JZgfXSqN",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator\n",
        "Model definition and creating discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97h2eMLeXS68",
        "colab_type": "code",
        "outputId": "1f14448b-09ef-4885-d2c2-4f7d56e0ad90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "def concc(y,x):  \n",
        "  inputs = tf.concat(values=[y,x], axis=1)\n",
        "  return inputs\n",
        "\n",
        "def get_discriminator():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial,activation='relu',input_shape=((2*n,))))\n",
        "  #model.add(tf.keras.layers.Dense(32,use_bias=True, kernel_initializer=randN_initial, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(1,use_bias=False, activation='sigmoid'))\n",
        "  return model\n",
        "discriminator = get_discriminator()\n",
        "\n",
        "discriminator.summary()\n",
        "\n",
        "#def discriminator(y,x):\n",
        "#    # Concatenate x and y\n",
        "#    inputs = tf.concat(values=[y,x], axis=1)\n",
        "#    #dense NN\n",
        "#    D_h1 = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
        "#    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
        "#    D_prob = tf.nn.sigmoid(D_logit)\n",
        "#    return D_prob, D_logit"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 320\n",
            "Trainable params: 320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnlfRYuYC8R",
        "colab_type": "text"
      },
      "source": [
        "## Data Generation, überhaupt noch relevant??!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcnkBIUXYa_",
        "colab_type": "text"
      },
      "source": [
        "## discriminator desicion????\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7im8FYMXeOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xQt6M5Xd9P",
        "colab_type": "text"
      },
      "source": [
        "## Define Loss\n",
        "strongly inspiered by: \\\\\n",
        "https://www.tensorflow.org/beta/tutorials/generative/dcgan?hl=en"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36yIH7Q3FiEq",
        "colab_type": "text"
      },
      "source": [
        "## defining Loss. TODO:\n",
        "compile the Model with the right loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCLjUsVDzAn",
        "colab_type": "code",
        "outputId": "f8618e8b-3f5e-41c3-d8b3-3d0de9fe6f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "real_training_data = tf.concat(values=[real_channel(x), x], axis=-1)  \n",
        "fake_training_data = tf.concat(values=[generator([x]),x], axis=-1)# training =True),x], axis=-1)\n",
        "\n",
        "tf.print(real_training_data.shape,fake_training_data.shape)\n",
        "real_output = discriminator(real_training_data)\n",
        "fake_output = discriminator(fake_training_data)\n",
        "tf.print(fake_output)\n",
        "tf.print(real_output)\n",
        "#print(real_output, fake_output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 8]) TensorShape([1000, 8])\n",
            "[[0.468297839]\n",
            " [0.49243772]\n",
            " [0.47628814]\n",
            " ...\n",
            " [0.481785595]\n",
            " [0.494748503]\n",
            " [0.484413177]]\n",
            "[[0.457779]\n",
            " [0.471689939]\n",
            " [0.483948708]\n",
            " ...\n",
            " [0.475092322]\n",
            " [0.483340025]\n",
            " [0.501586676]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERelQ5oTEMtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def discriminator_loss(real_output, fake_output):\n",
        "  #loss= -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "#  loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)  #Wasserstein GAN\n",
        "#  return loss\n",
        "\n",
        "def generator_loss(fake_output, generator):\n",
        "  return -tf.reduce_mean(fake_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCZBgwYBNYW",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8J9r3UpBNl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf249394-9c0f-44b9-8799-c8d9697cb64b"
      },
      "source": [
        "disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)   #use \"-\" sign to minimize rather than maximize loss\n",
        "gen_loss =  -tf.reduce_mean(fake_output)\n",
        "#disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output)) #-tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "#gen_loss =-tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        "tf.print(disc_loss, gen_loss)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)      #RMSprop   in oreder to test where the error comes from\n",
        "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)      #"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.00194364786 -0.47526446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gktABNcepz5c",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation with Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgM9lv-dp1PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_evaluation_data(batch_size=1000):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x))) #Average power normalization (not required if standard normal distribution is used )\n",
        "  #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "  #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "  fake_eval_data = tf.concat(values=[generator([x]), x], axis=1)\n",
        "  real_eval_data = tf.concat(values=[real_channel(x), x], axis=1) #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "  inputs = x\n",
        "  return  real_eval_data, fake_eval_data, inputs \n",
        "\n",
        "\n",
        "\n",
        "def get_evaluation_data(evaluation_per_epochs):\n",
        "  real_eval_data = []\n",
        "  fake_eval_data  = []\n",
        "  inputs = []\n",
        "  for i in range(evaluation_per_epochs):\n",
        "    data = generate_evaluation_data()\n",
        "    real_eval_data.append(data[0])\n",
        "    fake_eval_data.append(data[1])\n",
        "    inputs.append(data[2])\n",
        "  return real_eval_data, fake_eval_data, inputs\n",
        "\n",
        "\n",
        "def test_eval(real_eval_data,fake_eval_data,inputs):\n",
        "  hist_range = 2\n",
        "  \n",
        "  #inputs_ = tf.concat(values=[inputs, inputs],  axis=0)\n",
        "  \n",
        "  fake_output_hist = np.mean(fake_eval_data,axis=0)  # Changed from 0 to 1\n",
        "  real_output_hist = np.mean(real_eval_data,axis=0)\n",
        "  inputs_hist = np.mean(inputs,axis=0)\n",
        "    \n",
        "  fake_output_hist1 = np.reshape( fake_output_hist,[-1,])\n",
        "  real_output_hist1 = np.reshape( real_output_hist,[-1,])\n",
        "    \n",
        "  plt.hist(fake_output_hist1,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  plt.hist(real_output_hist1,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  plt.title(\"noise distribution\")\n",
        "  plt.legend([\"generator\", \"target\"])\n",
        "  plt.show()\n",
        "  tf.print(inputs_hist.shape)\n",
        "  \n",
        "  #fake_noise = np.reshape( fake_output_hist - inputs_hist,[-1,])\n",
        "  #real_noise = np.reshape( real_output_hist - inputs_hist,[-1,])\n",
        "   \n",
        "  #plt.hist(fake_noise,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')\n",
        "  #plt.hist(real_noise,bins=300,range=(-hist_range,hist_range),density=True,histtype='step')    \n",
        "  #plt.title(\"noise distribution after subtracting Inpus_noise\")\n",
        "  #plt.legend([\"generator\", \"target\"])\n",
        "  #plt.show()\n",
        "    \n",
        "    #print(\"decision for fake data was %d: and for real data was %d:\" % (decision_fake, decision_real))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXQWOgXnl62o",
        "colab_type": "text"
      },
      "source": [
        "### Define the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sl75gEZl6Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 2000\n",
        "steps_per_epoches = 100\n",
        "batch_size = 1000\n",
        "\n",
        "evaluation_per_epochs = 10\n",
        "\n",
        "seed = tf.random.normal([batch_size, n])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZUTZng_fFBk",
        "colab_type": "text"
      },
      "source": [
        "# Wasserstein clipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEFEdt29fEj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clip_D = [p.assign(tf.clip_by_value(p, -0.001, 0.001)) for p in discriminator.trainable_variables]\n",
        "\n",
        "#def get_disc_grad(trainable_variables):\n",
        "#  return [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in trainable_variables]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooDukkHvmduJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, steps_per_epoches , batch_size):\n",
        "  start = time.time()\n",
        "  counter = 0\n",
        "  epoch = 0\n",
        "  for epoch in range(epochs):\n",
        "    #print(massege_batch)\n",
        "    counter += 1\n",
        "\n",
        "    \n",
        "    train_step() \n",
        "    #tf.print(generator_optimizer.apply_gradients())\n",
        "    #if counter%5 == 0:\n",
        "    if counter%100==0:\n",
        "      tf.print(\"counter %d:\" % (counter))\n",
        "      fake_c = generator([x,generator_noise(x)])\n",
        "      tf.print(fake_c[0])\n",
        "    if counter%6 == 0 and counter<8:\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "    if counter%1000 == 0:\n",
        "      real_c = real_channel(x)\n",
        "      fake_c = generator([x,generator_noise(x)])\n",
        "      real_eval_data, fake_eval_data, inputs = get_evaluation_data(evaluation_per_epochs)\n",
        "      test_eval(real_eval_data, fake_eval_data, inputs)\n",
        "      tf.print(fake_c[0])\n",
        "      tf.print(disc_loss, gen_loss)\n",
        "    #print ('Time for epoch {} is {} sec,'.format(epoch + 1, time.time()-start))\n",
        "      tf.print ('Time for epoch {},'.format(epoch + 1))\n",
        "    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #print(x)\n",
        "    fake_c = generator([x,generator_noise(x)])\n",
        "    if tf.math.is_nan(fake_c[0,0]) == True:\n",
        "      print(\"doesn't train the generator as expacted\")\n",
        "      tf.debugging.check_numerics(fake_c,'message generator',name=None)\n",
        "      break # in order to finde wher the [nan] - prolem is cumming from\n",
        "    \n",
        "       \n",
        "  #checkpoint_path = \"training_1/cp.ckpt\"\n",
        "  #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  #cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "  #                                               save_weights_only=False,\n",
        "  #                                               verbose=1)    \n",
        "  tf.saved_model.save(generator,'/tmp/saved_model/')\n",
        "  tf.print ('Time for the training is {} sec,'.format( time.time()-start))\n",
        " # print(gradients_of_generator)  \n",
        "  \n",
        "\n",
        "  # Generate after the final epoch\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7H98i7TmVxw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XxSryMYmCkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@tf.function\n",
        "#def train_step(massege_batch,counter):\n",
        "#    x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "#    x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "    #G_n = tf.random.normal([tf.shape(x)[0],n],dtype=tf.float32) \n",
        "    #inputs = tf.concat(values=[x, G_n], axis=1)\n",
        "#    real_training_data = tf.concat(values=[real_channel(x), x], axis=1)  #tf.concat(values=[real_channel(x),x], axis=1)\n",
        "\n",
        "\n",
        " #   with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:           #tapes the gradient of the generaor an the discriminator\n",
        "  #    fake_training_data = tf.concat(values=[generator(x, training =True),x], axis=1)\n",
        "      \n",
        " #     real_output = discriminator(real_training_data, training=True)\n",
        " #     fake_output = discriminator(fake_training_data, training=True)\n",
        "\n",
        " #     disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        " #     gen_loss = -tf.reduce_mean(tf.math.log(fake_output))\n",
        "\n",
        " #     gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        " #     gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  #    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  #    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJno--QQh4_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(): #epoch, steps_per_epoches , batch_size, generator, discriminator):\n",
        "  x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "  x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "  for i in range(5):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      real_training_data = tf.concat(values=[real_channel(x), x], axis=1)\n",
        "      fake_training_data = tf.concat(values=[generator(x),x], axis=1)# training =True),x], axis=1)\n",
        "      real_output = discriminator(real_training_data)#, training=True)\n",
        "      fake_output = discriminator(fake_training_data)\n",
        "      \n",
        "      \n",
        "      #disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)  #use \"-\" sign to minimize rather than maximize loss\n",
        "      #gen_loss =  -tf.reduce_mean(fake_output)\n",
        "      #tf.print(real_training_data.shape, real_output[1].shape)\n",
        "      #tf.debugging.check_numerics(disc_loss,'loss generator',name=None)\n",
        "      # clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in gradients_of_discriminator]   \n",
        "      #tf.print(real_training_data[0])\n",
        "      \n",
        "      disc_loss = -tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output)) #-tf.reduce_mean(tf.math.log(real_output) + tf.math.log(1. - fake_output))   #use \"-\" sign to minimize rather than maximize loss\n",
        "      gen_loss =-tf.reduce_mean(tf.math.log(fake_output))\n",
        "      #disc_loss = tf.reduce_mean(real_output) - tf.reduce_mean(fake_output)   #use \"-\" sign to minimize rather than maximize loss\n",
        "      #gen_loss =  -tf.reduce_mean(fake_output)\n",
        "      #tf.print(disc_loss, gen_loss)\n",
        "      if tf.math.is_nan(disc_loss) == False:\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "        #tf.print(disc_loss, gen_loss)\n",
        "      if i == 4:  \n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "        #tf.print(disc_loss, gen_loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuGMDjc1metC",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y82FQj3Jmvxx",
        "colab_type": "code",
        "outputId": "565a5616-69a9-40e4-a89c-5a3a6aab7b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "train(epochs, steps_per_epoches , batch_size)\n",
        "print(generator(x)[1])\n",
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XuUVOWZ7/HvT4I2ijYKaJS7icYo\nFy8No2JUMFEmjmJGPcEkE52TSGLiMcMkM8HMnMjRnBkmuoaMJjmGSVjJnCiamDHibdQMXiJKBD0o\nikZRCXbrSIPShAhG8Dl/1K52U1R1V3fXrat+n7VqUftSez+1gafe/e53P1sRgZmZNY49qh2AmZlV\nlhO/mVmDceI3M2swTvxmZg3Gid/MrME48ZuZNRgnfqtpkrZKOrTM+3hA0ueT95+WdG8Jt/2MpFOT\n9/Mk/bSE2/6GpB+WanvWON5X7QDMuhIRgyu8vxuAG7pbT9KPgdaI+PtutndUKeJKfjx+GhEjU9v+\nh1Js2xqPW/xmZSDJjSqrWU78VnaS1kn6mqSnJHVIullSU2r5xZLWSnpD0hJJh6SWhaQPJu8/LmmN\npN9LapP0tdR6fyZplaTNkh6RNLGLeD4m6bkklu8CSi27SNLDyXtJWiBpg6QtklZLGi9pNvBp4G+T\nrqjbU9/z65KeAv4g6X3JvI+mdt+UfP/fS3pC0qR83zWZ/rGkb0naB7gbOCTZ31ZJh+R2HUk6O+la\n2px0X3242L8DayxO/FYp/w2YAYwDJgIXAUiaDvxjsvxg4HfATQW28SPgCxGxLzAeWJps4xhgEfAF\nYCjwA2CJpL1yNyBpGPDvwN8Dw4AXgakF9nc6cDJwONCcxLgpIhaS6Q76dkQMjoizUp+5ADgTGBIR\nO/Jscybwc+AA4Ebgl5IGFtg/ABHxB+BPgVeT/Q2OiFdzvtfhwGLgr4DhwF3A7ZL2TK2W9+/AGo8T\nv1XKtRHxakS8AdwOHJ3M/zSwKCKeiIi3gcuBEySNzbONd4AjJe0XEW9GxBPJ/NnADyLiNxGxMyJ+\nArwNHJ9nGx8HnomIWyLiHeA7wH8ViPkdYF/gCEAR8WxEvFbE93wlIrYVWP54at//DDQViLOnPgnc\nGRH3Jdu+BhgEnJgTW76/A2swTvxWKenk+haQvWh7CJlWPgARsRXYBIzIs41zySTu30l6UNIJyfwx\nwFeTLo7NkjYDo5Jt5zoEeCW1v0hPp0XEUuC7wPeADZIWStqvm++Zd1v5lkfEu0BrgTh7Kvc4vpvs\nK30cC/0dWINx4rdqe5VM4gYg6c8eCrTlrhgRKyJiJnAg8EvgZ8miV4D/HRFDUq+9I2Jxnv29RuZH\nIbs/pafz7PPaiDgOOJJMl8/fZBcV+kihbSXS+94DGEnmGEAmGe+dWvf9Pdhu7nHMfq/djqOZE79V\n22LgLyUdnfTJ/wPwm4hYl15J0p7JGPvmpCtjC/BusvhfgS9K+pPkguw+ks6UtG+e/d0JHCXpz5OR\nN5exa4JN73Nyss2BwB+A7al9vg705v6C41L7/isyXVLLk2WrgE9JGiBpBnBK6nOvA0MlNRfY7s+A\nMyWdlsT71WTbj/QiRqtzTvxWVRHxK+B/Ar8g0xr/ADCrwOp/AayTtAX4IpnrA0TESuBiMt0ybwJr\nKXDhMiI2AucD88l0KR0GLCuwv/3I/Ki8SaYbZRNwdbLsR2SuN2yW9Mvivi0At5Hpj38z+T5/nvyQ\nAXwFOAvYnHy3zu1GxHNkfiRfSva5S/dQRPwW+AxwHbAx2c5ZEfHHHsRmDUJ+EIuZWWNxi9/MrME4\n8ZuZNRgnfjOzBuPEb2bWYGqykNSwYcNi7Nix1Q7DzKzfePzxxzdGxPBi1q3JxD927FhWrlxZ7TDM\nzPoNSb/rfq0Md/WYmTUYJ34zswbjxG9m1mBqso/fzOrHO++8Q2trK9u3b692KHWhqamJkSNHMnBg\nl49x6JITv5mVVWtrK/vuuy9jx44lUzTUeisi2LRpE62trYwbN67X23FXj5mV1fbt2xk6dKiTfglI\nYujQoX0+e3LiN7Oyc9IvnVIcSyd+M7MG4z5+M6uoqfOX0ra50COJe27EkEEsmzu9ZNsrt+985zvM\nnj2bvffeu/uVy8SJ36w3FkzgtY5tnNe0sHNWf0o+1dS2eRvr5p9Zsu2NnXtnybZVChFBRLDHHvk7\nVL7zne/wmc98pkeJf+fOnQwYMKBUIbqrx6xXOtZzMO20bd7W+bLadtVVV/GhD32Ik046iQsuuIBr\nrrmGF198kRkzZnDcccfxkY98hOeeew6Aiy66iMsuu4wTTzyRQw89lFtuuaVzO1dffTWTJ09m4sSJ\nXHHFFQCsW7eOD33oQ3z2s59l/PjxvPLKK1xyySW0tLRw1FFHda537bXX8uqrrzJt2jSmTZsGwOLF\ni5kwYQLjx4/n61//eud+Bg8ezFe/+lUmTZrEo48+WtqDkf11KvQCFgEbgKcLLP8bMs8KXQU8DewE\nDkiWrQNWJ8tWdrev7Ou4444Ls5p2xX4RV+wXY75+R4z5+h3xyjcPjfjn8dWOqiatWbNml+kxX7+j\npNsvZnuPPfZYTJo0KbZt2xZbtmyJD37wg3H11VfH9OnT4/nnn4+IiOXLl8e0adMiIuLCCy+M8847\nL3bu3BnPPPNMfOADH4iIiHvuuScuvvjiePfdd2Pnzp1x5plnxoMPPhgvv/xySIpHH320c5+bNm2K\niIgdO3bEKaecEk8++WQm3jFjor29PSIi2traYtSoUbFhw4Z45513Ytq0aXHrrbdGRAQQN998c97v\nk3tMk/WLzrHFdPX8mMyzTP+twA/H1STPIZV0FjAnIt5IrTItMs85NatbI7UROqodhRWybNkyZs6c\nSVNTE01NTZx11lls376dRx55hPPPP79zvbfffrvz/TnnnMMee+zBkUceyeuvvw7Avffey7333ssx\nxxwDwNatW3nhhRcYPXo0Y8aM4fjjj+/8/M9+9jMWLlzIjh07eO2111izZg0TJ07cJa4VK1Zw6qmn\nMnx4pqjmpz/9aR566CHOOeccBgwYwLnnnluW49Ft4o+IhySNLXJ7F5B5ILRZ/7Rgwq7Tc1ZXJw4r\nu3fffZchQ4awatWqvMv32muvzveRPJs8Irj88sv5whe+sMu669atY5999umcfvnll7nmmmtYsWIF\n+++/PxdddFGPx943NTWVtF8/rWR9/JL2BmYAv0jNDuBeSY9Lmt3N52dLWilpZXt7e6nCMuuZjvW7\nvqwuTJ06ldtvv53t27ezdetW7rjjDvbee2/GjRvHz3/+cyCT1J988skut3PGGWewaNEitm7dCkBb\nWxsbNmzYbb0tW7awzz770NzczOuvv87dd9/duWzffffl97//PQBTpkzhwQcfZOPGjezcuZPFixdz\nyimnlOprF1TKUT1nActyunlOiog2SQcC90l6LiIeyvfhiFgILARoaWmJEsZlZjVkxJBBJR2JM2LI\noG7XmTx5MmeffTYTJ07koIMOYsKECTQ3N3PDDTdwySWX8K1vfYt33nmHWbNmMWnSpILbOf3003n2\n2Wc54YQTgMwF2J/+9Ke7tcwnTZrEMcccwxFHHMGoUaOYOnVq57LZs2czY8YMDjnkEO6//37mz5/P\ntGnTiAjOPPNMZs6c2csjUTxlT2G6XCnT1XNHRIzvYp1bgZ9HxI0Fls8DtkbENd3tr6WlJfwgFquK\nec050wU67pP1xm7P/HNf1/SprtdvYM8++ywf/vCHqx0GW7duZfDgwbz11lucfPLJLFy4kGOPPbba\nYfVKvmMq6fGIaCnm8yVp8UtqBk4BPpOatw+wR0T8Pnl/OnBlKfZnZtZTs2fPZs2aNWzfvp0LL7yw\n3yb9Uug28UtaDJwKDJPUClwBDASIiOuT1T4B3BsRf0h99CDg1qSuxPuAGyPiP0oXuplZ8W68MW9n\nREMqZlTPBUWs82Mywz7T814CCneWmZlZVfjOXTOzBuNaPWZd8bh+q0NO/GZd8Vh+q0NO/GY9kXsG\nADy812XQPNo/EsVaMKG0x6p5dJdnYps3b+bGG2/kS1/6Uun2mccDDzzAnnvuyYknnljW/ZSCE79Z\nT+RJWCO1EeZ07H4PgOXXsb609zt0c9w3b97M97///aITf7aQWaGyyoU88MADDB48uF8kfl/cNetO\n8+jMy/qluXPn8uKLL3L00UczZ84cTjvtNI499lgmTJjAbbfdBuQvq/yjH/2Iww8/nClTpnDxxRdz\n6aWXAtDe3s65557L5MmTmTx5MsuWLWPdunVcf/31LFiwgKOPPppf//rX1fzK3XKL36w72W4Et+j7\npfnz5/P000+zatUqduzYwVtvvcV+++3Hxo0bOf744zn77LMBeOGFF/jJT37C8ccfz6uvvspVV13F\nE088wb777sv06dM7Szl85StfYc6cOZx00kmsX7+eM844g2effZYvfvGLDB48mK997WvV/LpFceI3\nK6SIVv6IIYOgZ0UXrYoigm984xs89NBD7LHHHrS1tXWWXE6XVX7sscc45ZRTOOCAAwA4//zzef75\n5wH41a9+xZo1azq3uWXLls6ibf2FE79ZIQUuGL5Gpnb6wbRnHrc4L2eF7AVgD/2sOTfccAPt7e08\n/vjjDBw4kLFjx3aWS06XVe7Ku+++y/Lly2lqaipnqGXlPn6zHjph+79w8Ly1hVdwSeeaki6D3NHR\nwYEHHsjAgQO5//77+d3vfpf3M5MnT+bBBx/kzTffZMeOHfziF+9Vmz/99NO57rrrOqez9fzT+6l1\nbvGbWWU1jy7t9ZJuuuSGDh3K1KlTGT9+PJMnT+a5555jwoQJtLS0cMQRR+T9zIgRI/jGN77BlClT\nOOCAAzjiiCNobs7EfO211/LlL3+ZiRMnsmPHDk4++WSuv/56zjrrLM477zxuu+02rrvuOj7ykY+U\n7juWmBO/mVVWFbrAiinQ9vTTT+8y/alPfYrZs2ezY8cOPvGJT3DOOecAMGzYMG6++ebdPn/44Yfz\n1FNPlSbgMnNXj1lvNY/Oe0OX1Yd58+Zx9NFHM378eMaNG9eZ+OuBW/xmvTVntYd41rFrrun2mVH9\nllv8ZlZ2xTzpz4pTimPpxG9mZdXU1MSmTZuc/EsgIti0aVOfh5K6q8fMymrkyJG0trbS3t5e7VDq\nQlNTEyNHjuzTNpz4zXJvuHJdnpIaOHAg48aNq3YYluLEb5Z7s5XvuLU65z5+M7MG023il7RI0gZJ\nTxdYfqqkDkmrktc3U8tmSPqtpLWS5pYycDMz651iWvw/BmZ0s86vI+Lo5HUlgKQBwPeAPwWOBC6Q\ndGRfgjUzs77rNvFHxEPAG73Y9hRgbUS8FBF/BG4CZvZiO2ZmVkKl6uM/QdKTku6WdFQybwTwSmqd\n1mReXpJmS1opaaWHfZmZlU8pEv8TwJiImARcB/yyNxuJiIUR0RIRLcOHDy9BWGYl5kcwWp3oc+KP\niC0RsTV5fxcwUNIwoA0YlVp1ZDLPrH+as9pDPa0u9DnxS3q/JCXvpyTb3ASsAA6TNE7SnsAsYElf\n92dWTVPnL808brGL5Wa1rtsbuCQtBk4FhklqBa4ABgJExPXAecAlknYA24BZkSnKsUPSpcA9wABg\nUUQ8U5ZvYVYhbZu3sW7+mV0up/8+kc8aRLeJPyIu6Gb5d4HvFlh2F3BX70IzM7NycMkGs1JpHs3D\ncVm1ozDrlks2mJXKnNWM1MZqR2HWLbf4zbIWTOj5cM2u1s+t+mlWI5z4zbI61sO8jp59pquknlv1\n06xGuKvHzKzBOPGbmTUYJ34zswbjxG+NZ8GE9y68mjUgX9y1xuOLrtbg3OI3M2swTvxm5eASzlbD\nnPitMTWPLm8/f24JZ19XsBrixG+Nac7qyvb1d6z3tQWrGb64awbulrGG4sRvBq6nYw3FXT1mJdQa\nw3Y/e+hN8TezMnLiNyuhk96+dvezh471PqOwmuLEb2bWYJz4zSrJwzqtBvjirjWuco/lz+4jzUM6\nrQZ02+KXtEjSBklPF1j+aUlPSVot6RFJk1LL1iXzV0laWcrAzfqsEmP5c2/kMqsBxXT1/BiY0cXy\nl4FTImICcBWwMGf5tIg4OiJaeheimZmVUrddPRHxkKSxXSx/JDW5HBjZ97DMzKxcSn1x93PA3anp\nAO6V9Lik2V19UNJsSSslrWxvby9xWGZmllWyi7uSppFJ/CelZp8UEW2SDgTuk/RcRDyU7/MRsZCk\nm6ilpSVKFZeZme2qJC1+SROBHwIzI2JTdn5EtCV/bgBuBaaUYn9mZtZ7fU78kkYD/w78RUQ8n5q/\nj6R9s++B04G8I4PM6sWIIYMYO/dOps5fWu1QzArqtqtH0mLgVGCYpFbgCmAgQERcD3wTGAp8XxLA\njmQEz0HArcm89wE3RsR/lOE7mNWMZXOnAzB27p1VjsSssGJG9VzQzfLPA5/PM/8lYNLunzAzs2py\nyQazSqvEHcNmXXDiN6u0Sj/9yyyHa/VY41gwIZNwXRvfGpwTvzWOjvUwr2PXef4RsAbkxG+NrcgC\nah6eafXEid+sCG2bt1U7BLOS8cVdM7MG48RvZtZgnPitbkydv9R98WZFcB+/1Y1y98OPGDKorNs3\nqxQnfrMiZevwmPV37uoxM2swTvxmZg3Gid/MrMG4j9/qnythmu3Cid/qnythmu3Cid/6reyY/aJG\n27gYm1knJ37rt4oZtz91/lKWQdHF2MwagS/uWl2rVnG1EUMG7X4XcfNon3lYTXDit7pTC6Ubls2d\nvvuPzpzVPvOwmlBU4pe0SNIGSU8XWC5J10paK+kpScemll0o6YXkdWGpAjfLyk30bZu3lbSlP3X+\nUpdrsLpSbIv/x8CMLpb/KXBY8poN/B8ASQcAVwB/AkwBrpC0f2+DNcunmETflzOAts3bXK7B6kpR\niT8iHgLe6GKVmcC/RcZyYIikg4EzgPsi4o2IeBO4j65/QMxK6uG9LoPm0X6QillKqfr4RwCvpKZb\nk3mF5u9G0mxJKyWtbG9vL1FY1uhGamPV+tXzXuA1qwE1c3E3IhZGREtEtAwfPrza4Zj1Wd4LvGY1\noFSJvw0YlZoemcwrNN+sJEYMGeQLr2Y9VKrEvwT4bDK653igIyJeA+4BTpe0f3JR9/RknllJLJs7\n3RdezXqoqDt3JS0GTgWGSWolM1JnIEBEXA/cBXwcWAu8BfxlsuwNSVcBK5JNXRkRXV0kNquqqfOX\ndnbPZM8kfEZh9aaoxB8RF3SzPIAvF1i2CFjU89DMei6bpHP71rMXWrs7O2jbvI11888EYOzcOwE6\np8smWz3UN3dZhdTMxV2zUijU9VPTF1o71ruCqFWUE7/VrwUTaI1h1Y7CrOa4Oqf1O0WPje9Yz0lv\n38i6skZj1v848Vu/U0yXzYghg2B7/mU9quNvVofc1WN1qaukXuoibmb9jVv81i95iKVZ7znxW7/k\nbhqz3nNXj9U1nxmY7c6J3+pa+szA1TLNMpz4rWHU9E1cZhXkxG8NxdU8zXxx1xpMtusnW4fHrBG5\nxW9WQFnPDppHv1eczazC3OI3K6CsQ0bnrIZ5zeXbvlkX3OK3mjZ1/tKyjMRJj/Ap1z7MapUTv9W0\nYssr9LRbJj3Cp9wlHPzDYrXGXT1WF2r5Tl4PIbVa4xa/9StT5y+tr+GYCyZkLvT2kc8qrCfc4rd+\nIfss3BFDBtV0677HOtbDvI4+X+j1WYX1RLEPW58B/AswAPhhRMzPWb4AmJZM7g0cGBFDkmU7gezD\nRNdHxNmlCNwaS/pZuGbWN90mfkkDgO8BHwNagRWSlkTEmuw6ETEntf7/AI5JbWJbRBxdupCt0fTn\nrp107MU87N2sEopp8U8B1kbESwCSbgJmAmsKrH8BcEVpwjOrzIXbchVwS8fuu4WtVhRzcXcE8Epq\nujWZtxtJY4BxQPp/UJOklZKWSzqn15GalZELuFkjKfXF3VnALRGxMzVvTES0SToUWCppdUS8mPtB\nSbOB2QCjR/d9lIOZmeVXTIu/DRiVmh6ZzMtnFrA4PSMi2pI/XwIeYNf+//R6CyOiJSJahg8fXkRY\nZqXlyp3WKIpp8a8ADpM0jkzCnwV8KnclSUcA+wOPpubtD7wVEW9LGgZMBb5disDNSs0XXq1RdJv4\nI2KHpEuBe8gM51wUEc9IuhJYGRFLklVnATdFRKQ+/mHgB5LeJXN2MT89GsisbEp0Y5RZPSqqjz8i\n7gLuypn3zZzpeXk+9wjg2rNWGblljueszr9eYsSQQYyde6e7d6zh+M5dqx8d6997P6+j29XdtWON\nyonfalJD1J1xV5RViRO/1aRej6nvT8m0m66ovsj+cPqsxvJx4rf6UsZk2h9kE75vRrOuOPGb1REn\nfCuG6/GbmTUYJ34zswbjxG9WC5pH734fglmZOPGb1YI5q3e9D8GsjJz4zcwajBO/WQV1+VD0MnX3\n+EHslsvDOa1mNMJNR10Ot5yzuk8PXc/WHMrdh4d4Wi4nfqsZTlA9N3X+Uto2b2PEkEGdP5h+xKN1\nx4nfala9Vs3MPt+3FGc2bZu3sW7+mSWIyhqJE7/VrHrt8lk2d3pFWuXleoC89X++uGs1Z+r8pXXb\n2q8kP0DeCnGL32pOvXZf+MfMaoUTv1mF1GvXlfU/7uoxM2swbvGb1aLsjVx5ni/Q3f0O7lKy7hTV\n4pc0Q9JvJa2VNDfP8osktUtalbw+n1p2oaQXkteFpQzerG51rC9Yu6dt87YuL9oumzu980dhxJBB\n/iGw3XTb4pc0APge8DGgFVghaUlErMlZ9eaIuDTnswcAVwAtQACPJ599syTRmzWwYkY/+aYuy6eY\nFv8UYG1EvBQRfwRuAmYWuf0zgPsi4o0k2d8HzOhdqGaW1rZ5my8YW68Uk/hHAK+kpluTebnOlfSU\npFskjerhZ5E0W9JKSSvb29uLCMvqUa+6JhZMqJ9a9ulCba7Rb2VSqlE9twNjI2IimVb9T3q6gYhY\nGBEtEdEyfPjwEoVl/U26f7poXfSH9zvpuvyu0W9lUkzibwNGpaZHJvM6RcSmiHg7mfwhcFyxnzWz\nHM2jMy+zMilmOOcK4DBJ48gk7VnAp9IrSDo4Il5LJs8Gnk3e3wP8g6T9k+nTgcv7HLU1ti6GOtaF\nLr6Xy1lYKXSb+CNih6RLySTxAcCiiHhG0pXAyohYAlwm6WxgB/AGcFHy2TckXUXmxwPgyoh4owzf\nwxpJA3d/1Gs5C6usom7gioi7gLty5n0z9f5yCrTkI2IRsKgPMZo1tno/w7GK8527ZrWugc9wrDxc\nq8esCtK18v1MXKs0J36rD/1sJEy6Vn53JRg6LZjAw3tdVubIrBG4q8f6r/TNTY3Q/92xnpGqdhBW\nD5z4rep63c3Rsb7ftfTNaoETv1Vdnx4P2Agt/RLprpyzNQ738Zv1I60xrNf1e4q+lmB1z4nfrB85\n6e1rPbzT+syJ36wB+IEslubEb/1TnV3UTY/rL4deVT21uuXEb/3TnNV1cWE3W3QtPa7frNyc+K1/\nWTChrlr66adolbvVb5blxG/9S8f6umjp55O31Z/TpeV+eisFj+O3/mHBhPdu2KoTXSXx98bcJz9y\n85qT6ekwr9yRWb1z4rf+oWM9zOuodhQl1dXF1nTLf+r8pSyrREDWMNzVY1XhipTFa9u8bdcuHz+E\n3frILX6rCo9g6aH0dY05qzu7fsx6wy1+q7h8z431DUZmleMWv1Vc9rmxY+fe2TnPNxeZVY5b/Fa7\nFkxwX7ZZGRSV+CXNkPRbSWslzc2z/K8lrZH0lKT/lDQmtWynpFXJa0kpg7c617HeBcnMyqDbrh5J\nA4DvAR8DWoEVkpZExJrUav8PaImItyRdAnwb+GSybFtEHF3iuK2R1NndutXmuvxWTIt/CrA2Il6K\niD8CNwEz0ytExP0R8VYyuRwYWdowraHV8d26vdaHIZ2uy2/FJP4RwCup6dZkXiGfA+5OTTdJWilp\nuaRzCn1I0uxkvZXt7e1FhGX93Yghgxg7906P5imgy9o92R9CXwOxXijpqB5JnwFagFNSs8dERJuk\nQ4GlklZHxIu5n42IhcBCgJaWlihlXFZ9+boX3NXQtWVzp+8y8mk3vRjPn/2RdYu/sRXT4m8DRqWm\nRybzdiHpo8DfAWdHxNvZ+RHRlvz5EvAAcEwf4rV+Kptoeny3bp3V3a+2bF1+VwJtbMUk/hXAYZLG\nSdoTmAXsMjpH0jHAD8gk/Q2p+ftL2it5PwyYCqQvClsD6VHN+ewF3Tqpu19rXP+/sXXb1RMROyRd\nCtwDDAAWRcQzkq4EVkbEEuBqYDDwc0kA6yPibODDwA8kvUvmR2Z+zmggazBF9+fXYVE2s1pRVB9/\nRNwF3JUz75up9x8t8LlHAF99sk7u1+9evpIWZqXkkg1mNSSb8NNP5epS8+jMBd5st5hZEZz4zWpI\n7hlRt2dIc3Z9UEtv+IauxuPEb2XjhNI/+CJv43Hit7LpdUJxiQazsnJ1Tqs9LtHQc70o4eCx/I3L\nid+sHsxZ3eNKph7L37jc1WMl51ZkFWVb/T5jsi448VvJuRVZRdlWv38ArAtO/FZWrsBZQbkXxDvW\nd/sD4KJtjcmJ38qq6KGcbqH2Xe6xm9fcbb9/9u+nyyqgVnec+K0setzC71jfp4eLWB7ZMwA/vtJy\neFSPlUW2/G9R0pU4naRKpweVTT20s7E48Vv1pcftu/5+VXhoZ2NxV49Vx4IJ73XvpLmP36zs3OK3\nysv242fr7buFb1ZRbvFbyRTdR5x+yIpb+OWXvWjuY20JJ34rGfcR16jsQ9nT3WvpH4HOkVTzqxKe\nVZ4Tv/VJbunlvMM4PUa/NmTPtBZM2HXYbDKSKndkj8tp1y8nfuuTts3bdkkYeZNF7hh99+lXXvqY\nz1m9a+JvHg0d61k2d7pv5GoQTvzWZ0UljGx3A/gh6tWQe7aV7y5faxhFjeqRNEPSbyWtlTQ3z/K9\nJN2cLP+NpLGpZZcn838r6YzShW615OG9LuPhvS7LtCSz/cm5PEa/5o0YMogRQwbxaNNXaL3iA76p\nq0512+KXNAD4HvAxoBVYIWlJRKxJrfY54M2I+KCkWcA/AZ+UdCQwCzgKOAT4laTDI2Jnqb+IlViB\nfvmp85d2XsR9tOkrPLxXAGeDsteDAAAF50lEQVQyUhszK3Swaz9y+vPu469dSVfcsr2S6e3tMGQ0\nN2++GHixmpFZGRTT1TMFWBsRLwFIugmYCaQT/0xgXvL+FuC7kpTMvyki3gZelrQ22d6jpQnf+qzQ\nhdfkgl/rFR9ggMR5TQuBTJ/+uoOSk76OdlCB7aZHkriVX/vS/f7ZshlzVjNg3gdhXjOtMYxPDvpX\nX/CtE8Uk/hHAK6npVuBPCq0TETskdQBDk/nLcz47It9OJM0GZieTWyX9tojY8hkGbOzlZ8uptuP6\n60IZfEvy52mdc3Zb83+pi+mnM38U3H43cdWexolrl7/HLcBp6PIeb6Vxjldp9CWuMcWuWDMXdyNi\nIbCwr9uRtDIiWkoQUkk5rp5xXD3juHqm0eMq5uJuGzAqNT0ymZd3HUnvA5qBTUV+1szMKqiYxL8C\nOEzSOEl7krlYuyRnnSXAhcn784ClERHJ/FnJqJ9xwGHAY6UJ3czMeqPbrp6kz/5S4B5gALAoIp6R\ndCWwMiKWAD8C/m9y8fYNMj8OJOv9jMyF4B3AlyswoqfP3UVl4rh6xnH1jOPqmYaOS5mGuZmZNQqX\nZTYzazBO/GZmDabfJ35JV0t6TtJTkm6VNKTAel2WnShDXOdLekbSu5IKDs+StE7SakmrJK2sobgq\nfbwOkHSfpBeSP/cvsN7O5FitkpQ7yKCU8fS6TEk5FRHXRZLaU8fo8xWIaZGkDZKeLrBckq5NYn5K\n0rHljqnIuE6V1JE6Vt+sUFyjJN0vaU3yf/EredYp7zGLiH79Ak4H3pe8/yfgn/KsM4DMfeeHAnsC\nTwJHljmuDwMfAh4AWrpYbx0wrILHq9u4qnS8vg3MTd7Pzff3mCzbWoFj1O33B74EXJ+8nwXcXCNx\nXQR8t1L/npJ9ngwcCzxdYPnHgbvJ3Pt3PPCbGonrVOCOSh6rZL8HA8cm7/cFns/z91jWY9bvW/wR\ncW9E7Egml5O5VyBXZ9mJiPgjkC07Uc64no2I3t59XDZFxlXx45Vs/yfJ+58A55R5f10p5vun470F\nOC0pU1LtuCouIh4iM5qvkJnAv0XGcmCIpINrIK6qiIjXIuKJ5P3vgWfZvaJBWY9Zv0/8Of47mV/J\nXPnKTuQtHVEFAdwr6fGkbEUtqMbxOigiXkve/xdwUIH1miStlLRcUrl+HIr5/ruUKSFTnm5omeLp\nSVwA5ybdA7dIGpVneaXV8v+/EyQ9KeluSUdVeudJF+ExwG9yFpX1mNVMyYauSPoV8P48i/4uIm5L\n1vk7MvcK3FBLcRXhpIhok3QgcJ+k55KWSrXjKrmu4kpPRERIKjTOeExyvA4FlkpaHREuH/me24HF\nEfG2pC+QOStxZbX8niDz72mrpI8DvyRzk2lFSBoM/AL4q4jY0t36pdQvEn9EfLSr5ZIuAv4MOC2S\nDrIcZSkd0V1cRW6jLflzg6RbyZzO9ynxlyCuih8vSa9LOjgiXktOaTcU2Eb2eL0k6QEyraVSJ/6e\nlClp1a5lSsqp27giIh3DD8lcO6m2mizdkk62EXGXpO9LGhYRZS/eJmkgmaR/Q0T8e55VynrM+n1X\nj6QZwN8CZ0fEWwVWK6bsRMVJ2kfSvtn3ZC5U5x2BUGHVOF7psh8XArudmUjaX9JeyfthwFR2LQ9e\nKn0pU1JO3caV0w98Npn+42pbAnw2GalyPNCR6tarGknvz16XkTSFTD4s9483yT5/BDwbEf9cYLXy\nHrNKX9Eu9QtYS6YvbFXyyo60OAS4K7Xex8lcPX+RTJdHueP6BJl+ubeB14F7cuMiMzrjyeT1TK3E\nVaXjNRT4T+AF4FfAAcn8FuCHyfsTgdXJ8VoNfK6M8ez2/YEryTQwAJqAnyf//h4DDi33MSoyrn9M\n/i09CdwPHFGBmBYDrwHvJP+2Pgd8EfhislxkHub0YvL3VnCUW4XjujR1rJYDJ1YorpPIXNt7KpW3\nPl7JY+aSDWZmDabfd/WYmVnPOPGbmTUYJ34zswbjxG9m1mCc+M3MGowTv5lZg3HiNzNrMP8fTYtB\n4AJ6l8EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "counter 100:\n",
            "[-0.56082803 0.598076642 0.0309002791 0.0629930049]\n",
            "counter 200:\n",
            "[0.505711079 -0.173581839 -0.24757579 -0.326432]\n",
            "counter 300:\n",
            "[0.50294894 -0.252536029 -0.312747031 -0.182192877]\n",
            "counter 400:\n",
            "[0.298400879 -0.469749779 -0.0103566982 0.314207971]\n",
            "counter 500:\n",
            "[0.455710232 -0.687433958 -0.748060167 0.101548836]\n",
            "counter 600:\n",
            "[-0.428541809 0.905983925 -0.874071777 -0.812958]\n",
            "counter 700:\n",
            "[0.174096286 -0.338671863 -0.866592765 0.230819628]\n",
            "counter 800:\n",
            "[0.58008045 -0.277832896 0.284562618 -0.764735699]\n",
            "counter 900:\n",
            "[-0.33777532 0.636172295 -0.470399737 -0.735827744]\n",
            "counter 1000:\n",
            "[-0.775888085 0.42970252 1.54388595 0.20230484]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "[-0.824898899 0.0725632757 1.29466009 -0.100829542]\n",
            "-0.00194364786 -0.47526446\n",
            "Time for epoch 1000,\n",
            "counter 1100:\n",
            "[-0.618962765 0.627006114 -0.16863735 0.000854744576]\n",
            "counter 1200:\n",
            "[-1.07877314 1.32808161 0.474998027 -0.172663659]\n",
            "counter 1300:\n",
            "[-0.361384213 0.30990535 0.384803 -1.26515448]\n",
            "counter 1400:\n",
            "[1.00008488 -0.502467215 -0.747434497 -1.49833167]\n",
            "counter 1500:\n",
            "[0.0551664494 0.669591188 0.399970263 1.02917922]\n",
            "counter 1600:\n",
            "[0.322949 -0.118077122 0.137011111 0.36745742]\n",
            "counter 1700:\n",
            "[-0.168418214 -0.756969273 -0.183459476 -0.528071523]\n",
            "counter 1800:\n",
            "[0.393172294 -0.402436018 0.766986728 0.579286397]\n",
            "counter 1900:\n",
            "[-0.263924628 0.0533370562 -0.534329712 -0.330942929]\n",
            "counter 2000:\n",
            "[0.466067582 -0.479566574 -0.590448856 0.767108917]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n48RvZlZmnPjNzMrM/wchZGM6zDl4fgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(1000, 4)\n",
            "[0.755437553 -0.115581587 -0.657203138 0.538491964]\n",
            "-0.00194364786 -0.47526446\n",
            "Time for epoch 2000,\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /tmp/saved_model/assets\n",
            "Time for the training is 94.51271915435791 sec,\n",
            "tf.Tensor([ 0.24454866  0.13176322 -0.2164449   1.6042033 ], shape=(4,), dtype=float32)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal/shape [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RandomStandardNorma [(None, 4)]          0           tf_op_layer_random_normal/shape[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_RandomStandardNormal[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal (Tens [(None, 4)]          0           tf_op_layer_mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            20          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            20          tf_op_layer_random_normal[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,516\n",
            "Trainable params: 1,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 320\n",
            "Trainable params: 320\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 1min 49s, sys: 4.1 s, total: 1min 53s\n",
            "Wall time: 1min 34s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw6Rt5z3Rjud",
        "colab_type": "code",
        "outputId": "1fe2cd3c-2295-472f-b564-ad295cde139b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "x = tf.random.normal((batch_size,n),dtype=tf.dtypes.float32)    #randomly sample input data (\"fake\" AE messages)\n",
        "x = x/tf.sqrt(2*tf.reduce_mean(tf.square(x)))\n",
        "#print(x)\n",
        "real_c = real_channel(x)\n",
        "fake_c = generator([x])\n",
        "tf.print(real_c.shape)\n",
        "tf.print(fake_c.shape)\n",
        "\n",
        "#tf.debugging.check_numerics(fake_c,'message',name=None)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape([1000, 4])\n",
            "TensorShape([1000, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmP50TkiAg-C",
        "colab_type": "text"
      },
      "source": [
        "## AE\n",
        "Die Idee sollte sein das Training auf den encoder und decoder einzuschränken. Jedoch soll **end-to-end** trainiert werden, hierfür sollte vllt eine art Funktion eingesetzt werden, welche über die GAN's Layer zurück geht.\n",
        "Muss ich hierfür die Layer nochmals einzeln definieren?\n",
        "\n",
        "\n",
        "***Vermutung: Der Ausgang hat die 8fache dimension des Eingangs-> daher nur 1/8 richtig oder 7/8 richtig*** \\\\\n",
        "**zu klären: was passiert in meinem AE dass sie dei dimension ver8-facht von (1000,8) zu (8000,n)**\n",
        "**Kontrollieren was der output von meinem GAN ist**\n",
        "**Add complexity for higher rubustness**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiuN3SZYpeTU",
        "colab_type": "code",
        "outputId": "35ce5cd6-66d4-4025-b58b-04281f15f56b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def B_Ber(input_msg, msg):\n",
        "    '''Calculate the Batch Bit Error Rate'''\n",
        "    pred_error = tf.not_equal(tf.argmax(msg, 1), tf.argmax(input_msg, 1))\n",
        "    bber = tf.reduce_mean(tf.cast(pred_error, tf.float32))\n",
        "    return bber\n",
        "\n",
        "\n",
        "def get_encoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[M]))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='elu'))\n",
        "  #model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(n,use_bias=False, activation=None))\n",
        "  model.add(tf.keras.layers.Lambda(lambda x : tf.divide(x, tf.sqrt(2*tf.reduce_mean(tf.square(x))))))\n",
        "  return model\n",
        "\n",
        "def get_decoder():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.InputLayer(input_shape=[n]))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=True, activation='elu'))\n",
        "  #model.add(tf.keras.layers.Dense(M,use_bias=True, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(M,use_bias=False, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "encoder = get_encoder()\n",
        "decoder = get_decoder()\n",
        "\n",
        "encoder.summary()\n",
        "generator.summary()\n",
        "decoder.summary()\n",
        "   \n",
        "def get_AE(encoder, generator, decoder):\n",
        "  AE_model = tf.keras.Sequential()\n",
        "  AE_model.add(encoder)\n",
        "  AE_model.add(tf.keras.layers.Lambda(generator))\n",
        "  AE_model.add(decoder)\n",
        "  return AE_model\n",
        "\n",
        "#def test_Model(x):\n",
        "#  y = encoder(x)\n",
        "#  y = generator([y,make_zero(y)])\n",
        "#  y = decoder(y)\n",
        "#  return y\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "def generate_data_vector(length):\n",
        "  random_vector = tf.random.uniform(shape =(length,),minval=0,maxval=M, dtype=tf.dtypes.int32 ,seed=None,name=None)\n",
        "  random_hot_one_vector = tf.one_hot(random_vector, depth=M,on_value=1, off_value=0,axis=-1)\n",
        "  tf.print(random_hot_one_vector.shape)\n",
        "  return random_hot_one_vector\n",
        "\n",
        "data, test_data = generate_data_vector(10000000), generate_data_vector(10000)\n",
        "#print(data)\n",
        "\n",
        "#model = Autoencoder()\n",
        "AE = get_AE(encoder, generator, decoder)\n",
        "AE.compile(optimizer='nadam',loss='categorical_crossentropy',metrics=[B_Ber])\n",
        "history = AE.fit(data, data, batch_size=500,steps_per_epoch=1000, epochs=6)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 4)                 16        \n",
            "_________________________________________________________________\n",
            "lambda_2 (Lambda)            (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal/shape [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RandomStandardNorma [(None, 4)]          0           tf_op_layer_random_normal/shape[0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_mul (TensorFlowOpLa [(None, 4)]          0           tf_op_layer_RandomStandardNormal[\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_random_normal (Tens [(None, 4)]          0           tf_op_layer_mul[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            20          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4)            20          tf_op_layer_random_normal[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8)            0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           288         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4)            132         dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,516\n",
            "Trainable params: 1,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 4)                 20        \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 4)                 16        \n",
            "=================================================================\n",
            "Total params: 36\n",
            "Trainable params: 36\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TensorShape([10000000, 4])\n",
            "TensorShape([10000, 4])\n",
            "Train on 10000000 samples\n",
            "Epoch 1/6\n",
            "  491000/10000000 [>.............................] - ETA: 1:27 - loss: 0.4677 - B_Ber: 0.1138Epoch 2/6\n",
            "  494500/10000000 [>.............................] - ETA: 54s - loss: 0.0103 - B_Ber: 0.0000e+00Epoch 3/6\n",
            "  495500/10000000 [>.............................] - ETA: 53s - loss: 0.0030 - B_Ber: 0.0000e+00Epoch 4/6\n",
            "  500000/10000000 [>.............................] - ETA: 53s - loss: 0.0014 - B_Ber: 0.0000e+00Epoch 5/6\n",
            "  493000/10000000 [>.............................] - ETA: 53s - loss: 7.9322e-04 - B_Ber: 0.0000e+00Epoch 6/6\n",
            "  498000/10000000 [>.............................] - ETA: 54s - loss: 4.5910e-04 - B_Ber: 0.0000e+00"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ZsnSNgM7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def analytic_channel(input): \n",
        "  #print(input.shape)\n",
        "  return input + tf.random.normal(tf.shape(input), mean=0.0, stddev=noise_std)\n",
        "\n",
        "def real_transmision(test_data):\n",
        "  y = encoder(test_data)\n",
        "  y = generator(y)\n",
        "  y = decoder(y)\n",
        "  return y\n",
        "  #model = tf.keras.Sequential()\n",
        "  #model.add(encoder)\n",
        "  #model.add(tf.keras.layers.Lambda(generator))\n",
        "  #model.add(tf.keras.layers.Lambda(real_channel))\n",
        "  #model.add(decoder)\n",
        "  #return model\n",
        "\n",
        "def test_diff_eval(test_data, results):\n",
        "  diff = []\n",
        "  for i in range(tf.shape(test_data)[0]):\n",
        "    diff.append(tf.math.subtract(test_data[i,:], results[i,:]))\n",
        "  return diff\n",
        "    \n",
        "  \n",
        "real_AE = real_transmision(test_data)\n",
        "testTest = tf.dtypes.cast(real_AE + tf.constant(0.1,dtype=tf.float32,shape=tf.shape(real_AE)), tf.int32)\n",
        "\n",
        "diff_test =  test_diff_eval(test_data, testTest) \n",
        "#t = tf.math.subtract(test_data[1,:], real_AE[1,:])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntX-i_2J76v",
        "colab_type": "code",
        "outputId": "eb017b6e-4bd5-4f60-97fd-d4a669138539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.print(sum(diff_test))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5B2TUanPC5d",
        "colab_type": "code",
        "outputId": "20fc1bf6-1245-475d-afbe-d3583fcf2867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= encoder.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAD8CAYAAAC/+/tYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nupQBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8o3nqP_0OTK",
        "colab_type": "code",
        "outputId": "f8bb09fa-d925-48b1-bfcc-76e82bb14fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "tes_data = np.eye(M, dtype = int)\n",
        "coding= AE.predict(tes_data)\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.plot(coding[:,0], coding[:,1],\"b.\")\n",
        "plt.gca().set_ylim(-2,2)\n",
        "plt.gca().set_xlim(-2,2)\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAD8CAYAAAC/+/tYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1Ox/ABEH840lEPqrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SR4RrE3nqTc",
        "colab_type": "text"
      },
      "source": [
        "## Create and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi_IcVrbnS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}